# ================= ai_rag_system.py =================
import httpx
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

# ===================== CONFIG =====================
QDRANT_URL = "http://160.22.161.120:6333"
COLLECTION_NAME = "vietnam_laws"
MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"
TOP_K = 3

# ===================== INIT =====================
print("K·∫øt n·ªëi Qdrant...")
client = QdrantClient(
    url=QDRANT_URL,
    timeout=60,
    check_compatibility=False
)

print("Load embedding model...")
model = SentenceTransformer(MODEL_NAME)

# ===================== SEARCH (HTTP /points/search - COMPAT) =====================
def search_law_y_te(question: str) -> str:
    """
    Search LU·∫¨T Y T·∫æ b·∫±ng HTTP endpoint /points/search (t∆∞∆°ng th√≠ch Qdrant server c≈©/m·ªõi)
    """
    query_vector = model.encode(question).tolist()

    url = f"{QDRANT_URL}/collections/{COLLECTION_NAME}/points/search"
    payload = {
        "vector": query_vector,
        "limit": TOP_K,
        "with_payload": True
    }

    r = httpx.post(url, json=payload, timeout=60)
    r.raise_for_status()

    data = r.json() or {}
    points = data.get("result") or []

    if not points:
        return "Kh√¥ng t√¨m th·∫•y quy ƒë·ªãnh ph√°p lu·∫≠t y t·∫ø ph√π h·ª£p."

    answers = []
    for p in points:
        payload = p.get("payload") or {}
        answers.append(
            f"üìò {payload.get('LawName')} {payload.get('LawYear')} ‚Äì "
            f"ƒêi·ªÅu {payload.get('Article')}, Kho·∫£n {payload.get('Clause')}:\n"
            f"{payload.get('Content')}"
        )

    return "\n\n".join(answers)

# ===================== CLI =====================
if __name__ == "__main__":
    print("\nH·ªèi v·ªÅ LU·∫¨T Y T·∫æ (g√µ 'exit' ƒë·ªÉ tho√°t)\n")

    while True:
        q = input("‚ùì C√¢u h·ªèi: ").strip()
        if q.lower() in {"exit", "quit"}:
            break

        print("\n--- K·∫æT QU·∫¢ ---")
        print(search_law_y_te(q))
        print("----------------\n")
