"""
Module xá»­ lÃ½ truy váº¥n trá»±c tiáº¿p file Excel vá» KCN/CCN
TÃ­ch há»£p vÃ o chatbot Ä‘á»ƒ tráº£ vá» dá»¯ liá»‡u dáº¡ng JSON khi ngÆ°á»i dÃ¹ng há»i
vá» sá»‘ lÆ°á»£ng hoáº·c danh sÃ¡ch khu/cá»¥m cÃ´ng nghiá»‡p.

âœ… Bá»” SUNG:
- Load industrial_zones.geojson (tuá»³ chá»n) Ä‘á»ƒ gáº¯n tá»a Ä‘á»™ cho tá»«ng KCN/CCN
- Tráº£ JSON cÃ³ thÃªm:
    - data[i]["coordinates"] = [lng, lat] (náº¿u match Ä‘Æ°á»£c)
    - not_found_coordinates: danh sÃ¡ch tÃªn khÃ´ng match Ä‘Æ°á»£c tá»a Ä‘á»™
"""

import pandas as pd
import re
import json
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# RapidFuzz (khuyáº¿n nghá»‹). Náº¿u khÃ´ng cÃ³ sáº½ dÃ¹ng fallback match cÆ¡ báº£n.
try:
    from rapidfuzz import fuzz, process
except Exception:
    fuzz = None
    process = None


class ExcelQueryHandler:
    def __init__(
        self,
        excel_path: str,
        geojson_path: Optional[str] = None,
        match_threshold: int = 82,
        llm=None
    ):
        """
        Khá»Ÿi táº¡o handler vá»›i Ä‘Æ°á»ng dáº«n file Excel

        Args:
            excel_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file Excel chá»©a thÃ´ng tin KCN/CCN
            geojson_path: (tuá»³ chá»n) ÄÆ°á»ng dáº«n industrial_zones.geojson Ä‘á»ƒ gáº¯n tá»a Ä‘á»™
            match_threshold: ngÆ°á»¡ng match tÃªn (RapidFuzz) Ä‘á»ƒ cháº¥p nháº­n tá»a Ä‘á»™
            llm: Language model Ä‘á»ƒ xá»­ lÃ½ prompt-based (Báº®T BUá»˜C)
        """
        self.excel_path = excel_path
        self.df: Optional[pd.DataFrame] = None
        self.llm = llm

        if not self.llm:
            print("âš ï¸ WARNING: Há»‡ thá»‘ng prompt-based cáº§n LLM. Sáº½ fallback vá» keyword náº¿u cáº§n.")

        self.match_threshold = match_threshold
        self.geojson_path = geojson_path

        # LÆ°u index map toáº¡ Ä‘á»™: name_norm -> [lng, lat]
        self._iz_name_to_coord: Dict[str, List[float]] = {}
        self._iz_names_original: List[str] = []
        self._iz_names_norm: List[str] = []

        # Khai bÃ¡o cÃ¡c cá»™t cáº§n thiáº¿t
        self.columns_map = {
            "province": None,
            "type": None,  # Cá»™t Loáº¡i (KCN/CCN)
            "name": None,
            "address": None,
            "operation_time": None,
            "area": None,
            "rental_price": None,
            "industry": None
        }

        self._load_excel()
        self._load_geojson_if_provided()

    # ==========================================================
    # ğŸ§© LOAD FILE EXCEL & NHáº¬N DIá»†N Cá»˜T
    # ==========================================================
    def _load_excel(self):
        """Load file Excel vÃ  tá»± Ä‘á»™ng phÃ¡t hiá»‡n cÃ¡c cá»™t quan trá»ng"""
        try:
            self.df = pd.read_excel(self.excel_path)
            self.df.columns = self.df.columns.str.strip()

            for col in self.df.columns:
                col_lower = col.lower()
                if any(k in col_lower for k in ["tá»‰nh", "thÃ nh phá»‘", "province"]):
                    self.columns_map["province"] = col
                elif any(k in col_lower for k in ["loáº¡i", "loai", "type"]):
                    self.columns_map["type"] = col
                elif any(k in col_lower for k in ["tÃªn", "ten", "kcn", "ccn"]) and "loáº¡i" not in col_lower:
                    self.columns_map["name"] = col
                elif any(k in col_lower for k in ["Ä‘á»‹a chá»‰", "dia chi", "address"]):
                    self.columns_map["address"] = col
                elif any(k in col_lower for k in ["thá»i gian", "váº­n hÃ nh", "operation"]):
                    self.columns_map["operation_time"] = col
                elif any(k in col_lower for k in ["diá»‡n tÃ­ch", "dien tich", "area"]):
                    self.columns_map["area"] = col
                elif any(k in col_lower for k in ["giÃ¡ thuÃª", "gia thue", "rent", "rental"]):
                    self.columns_map["rental_price"] = col
                elif any(k in col_lower for k in ["ngÃ nh nghá»", "nganh nghe", "industry"]):
                    self.columns_map["industry"] = col

            print(f"âœ… ÄÃ£ load Excel: {len(self.df)} báº£n ghi")
            print("ğŸ§­ Cáº¥u trÃºc cá»™t nháº­n diá»‡n Ä‘Æ°á»£c:")
            for key, val in self.columns_map.items():
                print(f"   - {key}: {val}")

        except Exception as e:
            print(f"âŒ Lá»—i khi load Excel: {e}")
            self.df = None

    # ==========================================================
    # ğŸ—ºï¸ LOAD GEOJSON (industrial_zones.geojson) Ä‘á»ƒ gáº¯n tá»a Ä‘á»™
    # ==========================================================
    def _load_geojson_if_provided(self):
        """
        Load GeoJSON náº¿u cÃ³ path.
        Káº¿t quáº£: map name_norm -> [lng, lat]
        """
        if not self.geojson_path:
            return

        p = Path(self.geojson_path)
        if not p.exists():
            print(f"âš ï¸ GeoJSON khÃ´ng tá»“n táº¡i: {self.geojson_path} (bá» qua gáº¯n tá»a Ä‘á»™)")
            return

        try:
            with open(p, "r", encoding="utf-8") as f:
                gj = json.load(f)

            features = gj.get("features", []) or []
            name_to_coord: Dict[str, List[float]] = {}

            iz_names_original: List[str] = []
            iz_names_norm: List[str] = []

            for fe in features:
                props = fe.get("properties", {}) or {}
                geom = fe.get("geometry", {}) or {}
                coords = geom.get("coordinates")

                name = str(props.get("name", "")).strip()
                if not name:
                    continue

                # Chá»‰ há»— trá»£ Point [lng, lat] nhÆ° file cá»§a báº¡n Ä‘ang dÃ¹ng
                if isinstance(coords, list) and len(coords) == 2 and all(isinstance(x, (int, float)) for x in coords):
                    n = self._normalize_text(name)
                    name_to_coord[n] = [float(coords[0]), float(coords[1])]
                    iz_names_original.append(name)
                    iz_names_norm.append(n)

            self._iz_name_to_coord = name_to_coord
            self._iz_names_original = iz_names_original
            self._iz_names_norm = iz_names_norm

            print(f"âœ… ÄÃ£ load GeoJSON IZ: {len(self._iz_name_to_coord)} Ä‘iá»ƒm cÃ³ tá»a Ä‘á»™")

        except Exception as e:
            print(f"âš ï¸ Lá»—i load GeoJSON: {e}. (bá» qua gáº¯n tá»a Ä‘á»™)")

    # ==========================================================
    # ğŸ¤– PROMPT-BASED QUERY ANALYSIS
    # ==========================================================
    def _analyze_query_with_llm(self, question: str) -> Dict[str, Any]:
        """
        Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch toÃ n bá»™ cÃ¢u há»i vÃ  tráº£ vá» thÃ´ng tin cáº§n thiáº¿t
        
        Returns:
            {
                "is_industrial_query": bool,
                "province": str or None,
                "query_type": "KCN" | "CCN" | None (None = táº¥t cáº£),
                "search_type": "province" | "specific_name",
                "specific_name": str or None,
                "confidence": float,
                "reasoning": str
            }
        """
        if not self.llm or self.df is None:
            # Fallback vá» keyword náº¿u khÃ´ng cÃ³ LLM
            return self._fallback_keyword_analysis(question)
        
        # Láº¥y danh sÃ¡ch tá»‰nh cÃ³ trong dá»¯ liá»‡u
        available_provinces = self.df[self.columns_map["province"]].dropna().unique().tolist()
        available_provinces_str = ", ".join(available_provinces)
        
        # Láº¥y má»™t sá»‘ tÃªn KCN/CCN máº«u Ä‘á»ƒ LLM hiá»ƒu format
        sample_names = []
        if self.columns_map["name"] is not None:
            sample_names = self.df[self.columns_map["name"]].dropna().head(10).tolist()
        sample_names_str = ", ".join(sample_names[:5]) if sample_names else "KhÃ´ng cÃ³ dá»¯ liá»‡u máº«u"
        
        prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch cÃ¢u há»i vá» khu cÃ´ng nghiá»‡p vÃ  cá»¥m cÃ´ng nghiá»‡p Viá»‡t Nam.

DANH SÃCH Tá»ˆNH/THÃ€NH PHá» CÃ“ Dá»® LIá»†U:
{available_provinces_str}

Má»˜T Sá» TÃŠN KCN/CCN MáºªU:
{sample_names_str}

CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: "{question}"

NHIá»†M Vá»¤: PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  tráº£ vá» JSON vá»›i cÃ¡c thÃ´ng tin sau:

1. "is_industrial_query": true/false
   - true náº¿u cÃ¢u há»i vá» khu cÃ´ng nghiá»‡p (KCN) hoáº·c cá»¥m cÃ´ng nghiá»‡p (CCN)
   - false náº¿u khÃ´ng liÃªn quan

2. "search_type": "province" hoáº·c "specific_name"
   - "province" náº¿u ngÆ°á»i dÃ¹ng há»i vá» KCN/CCN trong má»™t tá»‰nh/thÃ nh phá»‘
   - "specific_name" náº¿u ngÆ°á»i dÃ¹ng há»i vá» má»™t KCN/CCN cá»¥ thá»ƒ theo tÃªn

3. "province": tÃªn tá»‰nh/thÃ nh phá»‘ (chá»‰ khi search_type = "province")
   - TrÃ­ch xuáº¥t tÃªn tá»‰nh tá»« cÃ¢u há»i
   - Pháº£i khá»›p CHÃNH XÃC vá»›i má»™t trong cÃ¡c tá»‰nh trong danh sÃ¡ch
   - Tráº£ vá» null náº¿u khÃ´ng tÃ¬m tháº¥y hoáº·c khÃ´ng khá»›p

4. "specific_name": tÃªn KCN/CCN cá»¥ thá»ƒ (chá»‰ khi search_type = "specific_name")
   - TrÃ­ch xuáº¥t tÃªn KCN/CCN tá»« cÃ¢u há»i
   - Bao gá»“m cáº£ tá»« khÃ³a "KHU CÃ”NG NGHIá»†P" hoáº·c "Cá»¤M CÃ”NG NGHIá»†P" náº¿u cÃ³

5. "query_type": loáº¡i truy váº¥n - QUAN TRá»ŒNG: PHÃ‚N BIá»†T RÃ• RÃ€NG
   - "KCN" náº¿u cÃ¢u há»i CHá»ˆ NHáº®C Äáº¾N "khu cÃ´ng nghiá»‡p", "kcn", "khu cn", "khu" (vÃ  KHÃ”NG cÃ³ "cá»¥m")
   - "CCN" náº¿u cÃ¢u há»i CHá»ˆ NHáº®C Äáº¾N "cá»¥m cÃ´ng nghiá»‡p", "ccn", "cá»¥m cn", "cá»¥m" (vÃ  KHÃ”NG cÃ³ "khu")
   - null chá»‰ khi cÃ¢u há»i NHáº®C Äáº¾N Cáº¢ HAI: "khu vÃ  cá»¥m", "kcn vÃ  ccn", "khu cÃ´ng nghiá»‡p vÃ  cá»¥m cÃ´ng nghiá»‡p"

6. "confidence": Ä‘á»™ tin cáº­y (0.0-1.0)
   - Má»©c Ä‘á»™ cháº¯c cháº¯n vá» phÃ¢n tÃ­ch

7. "reasoning": lÃ½ do phÃ¢n tÃ­ch
   - Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao phÃ¢n tÃ­ch nhÆ° váº­y

QUAN TRá»ŒNG - PHÃ‚N BIá»†T QUERY_TYPE:
- Náº¿u cÃ¢u há»i chá»‰ cÃ³ "khu" hoáº·c "kcn" (vÃ  KHÃ”NG cÃ³ "cá»¥m") â†’ query_type = "KCN"
- Náº¿u cÃ¢u há»i chá»‰ cÃ³ "cá»¥m" hoáº·c "ccn" (vÃ  KHÃ”NG cÃ³ "khu") â†’ query_type = "CCN"  
- Náº¿u cÃ¢u há»i cÃ³ cáº£ "khu" vÃ  "cá»¥m" â†’ query_type = null
- "cÃ´ng nghiá»‡p" khÃ´ng quyáº¿t Ä‘á»‹nh loáº¡i, chá»‰ cÃ³ "khu" vs "cá»¥m" má»›i quyáº¿t Ä‘á»‹nh
- LUÃ”N LUÃ”N kiá»ƒm tra xem cÃ¢u há»i cÃ³ cáº£ "khu" vÃ  "cá»¥m" khÃ´ng trÆ°á»›c khi quyáº¿t Ä‘á»‹nh
- VÃ­ dá»¥: "cá»¥m cÃ´ng nghiá»‡p á»Ÿ VÄ©nh Long" â†’ chá»‰ cÃ³ "cá»¥m", khÃ´ng cÃ³ "khu" â†’ query_type = "CCN"
- VÃ­ dá»¥: "khu cÃ´ng nghiá»‡p á»Ÿ HÃ  Ná»™i" â†’ chá»‰ cÃ³ "khu", khÃ´ng cÃ³ "cá»¥m" â†’ query_type = "KCN"

BÆ¯á»šC PHÃ‚N TÃCH QUERY_TYPE:
1. TÃ¬m tá»« "khu" hoáº·c "kcn" trong cÃ¢u há»i â†’ has_khu = true/false
2. TÃ¬m tá»« "cá»¥m" hoáº·c "ccn" trong cÃ¢u há»i â†’ has_cum = true/false  
3. Náº¿u has_khu = true vÃ  has_cum = true â†’ query_type = null
4. Náº¿u has_khu = true vÃ  has_cum = false â†’ query_type = "KCN"
5. Náº¿u has_khu = false vÃ  has_cum = true â†’ query_type = "CCN"
6. Náº¿u has_khu = false vÃ  has_cum = false â†’ query_type = null

VÃ Dá»¤ SEARCH_TYPE = "province":
- "khu cÃ´ng nghiá»‡p á»Ÿ HÃ  Ná»™i" â†’ {{"query_type": "KCN", "reasoning": "Chá»‰ há»i vá» KHU cÃ´ng nghiá»‡p, khÃ´ng nháº¯c Ä‘áº¿n cá»¥m"}}
- "cá»¥m cÃ´ng nghiá»‡p á»Ÿ BÃ¬nh DÆ°Æ¡ng" â†’ {{"query_type": "CCN", "reasoning": "Chá»‰ há»i vá» Cá»¤M cÃ´ng nghiá»‡p, khÃ´ng nháº¯c Ä‘áº¿n khu"}}
- "khu vÃ  cá»¥m cÃ´ng nghiá»‡p á»Ÿ ÄÃ  Náºµng" â†’ {{"query_type": null, "reasoning": "Há»i vá» Cáº¢ HAI khu vÃ  cá»¥m"}}
- "danh sÃ¡ch cá»¥m cÃ´ng nghiá»‡p á»Ÿ BÃ¬nh DÆ°Æ¡ng" â†’ {{"query_type": "CCN", "reasoning": "Chá»‰ há»i vá» Cá»¤M cÃ´ng nghiá»‡p, khÃ´ng nháº¯c Ä‘áº¿n khu"}}
- "váº½ biá»ƒu Ä‘á»“ cá»¥m cÃ´ng nghiá»‡p á»Ÿ Háº£i PhÃ²ng" â†’ {{"query_type": "CCN", "reasoning": "Chá»‰ há»i vá» Cá»¤M cÃ´ng nghiá»‡p, khÃ´ng nháº¯c Ä‘áº¿n khu"}}

VÃ Dá»¤ SEARCH_TYPE = "specific_name":
- "cho tÃ´i thÃ´ng tin vá» KHU CÃ”NG NGHIá»†P NGÅ¨ Láº C - VÄ¨NH LONG" â†’ {{"query_type": "KCN", "reasoning": "TÃ¬m KCN cá»¥ thá»ƒ"}}
- "thÃ´ng tin vá» cá»¥m cÃ´ng nghiá»‡p ABC" â†’ {{"query_type": "CCN", "reasoning": "TÃ¬m CCN cá»¥ thá»ƒ"}}

CHá»ˆ TRáº¢ Vá»€ JSON (khÃ´ng cÃ³ markdown, khÃ´ng cÃ³ text thÃªm):
"""

        try:
            from langchain_core.messages import HumanMessage
            
            # Kiá»ƒm tra LLM cÃ³ kháº£ dá»¥ng khÃ´ng
            if not hasattr(self.llm, 'invoke'):
                print("âš ï¸ LLM does not have invoke method")
                return self._fallback_keyword_analysis(question)
            
            # Gá»i LLM vá»›i error handling
            try:
                llm_response = self.llm.invoke([HumanMessage(content=prompt)])
                if not llm_response or not hasattr(llm_response, 'content'):
                    print("âš ï¸ LLM returned invalid response object")
                    return self._fallback_keyword_analysis(question)
                
                response = llm_response.content
                if not isinstance(response, str):
                    response = str(response)
                
                response = response.strip()
                
            except Exception as llm_error:
                print(f"âš ï¸ LLM invoke error: {llm_error}")
                return self._fallback_keyword_analysis(question)
            
            # Kiá»ƒm tra response cÃ³ rá»—ng khÃ´ng
            if not response:
                print("âš ï¸ LLM returned empty response")
                return self._fallback_keyword_analysis(question)
            
            # Debug: In ra response Ä‘á»ƒ kiá»ƒm tra (chá»‰ khi cÃ³ lá»—i)
            # print(f"ğŸ” LLM raw response: '{response}'")
            
            # Thá»­ parse JSON
            import json
            try:
                result = json.loads(response)
            except json.JSONDecodeError as json_error:
                # Chá»‰ log lá»—i náº¿u response khÃ´ng rá»—ng
                if response.strip():
                    print(f"âš ï¸ JSON parse error: {json_error}")
                else:
                    print("âš ï¸ Empty response from LLM")
                    return self._fallback_keyword_analysis(question)
                
                # Thá»­ extract JSON tá»« response náº¿u cÃ³ markdown format
                import re
                
                # Loáº¡i bá» markdown code blocks
                cleaned_response = response.strip()
                if cleaned_response.startswith('```json'):
                    cleaned_response = cleaned_response[7:]  # Bá» ```json
                if cleaned_response.startswith('```'):
                    cleaned_response = cleaned_response[3:]   # Bá» ```
                if cleaned_response.endswith('```'):
                    cleaned_response = cleaned_response[:-3]  # Bá» ```
                
                cleaned_response = cleaned_response.strip()
                
                # Kiá»ƒm tra cleaned response cÃ³ rá»—ng khÃ´ng
                if not cleaned_response:
                    print("âš ï¸ Cleaned response is empty")
                    return self._fallback_keyword_analysis(question)
                
                # Thá»­ parse láº¡i
                try:
                    result = json.loads(cleaned_response)
                    # print("âœ… Successfully parsed cleaned JSON")
                except json.JSONDecodeError:
                    # Thá»­ tÃ¬m JSON object trong text
                    json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', cleaned_response, re.DOTALL)
                    if json_match:
                        try:
                            result = json.loads(json_match.group())
                            # print("âœ… Successfully extracted JSON from response")
                        except:
                            print("âŒ Failed to extract JSON from response")
                            return self._fallback_keyword_analysis(question)
                    else:
                        print("âŒ No JSON found in response")
                        return self._fallback_keyword_analysis(question)
            
            # Validate result
            required_keys = ["is_industrial_query", "search_type", "province", "specific_name", "query_type", "confidence", "reasoning"]
            if not isinstance(result, dict):
                print(f"âš ï¸ LLM response is not a dict: {type(result)}")
                return self._fallback_keyword_analysis(question)
                
            if not all(key in result for key in required_keys):
                missing_keys = [key for key in required_keys if key not in result]
                print(f"âš ï¸ LLM response missing keys: {missing_keys}")
                return self._fallback_keyword_analysis(question)
            
            return result
                
        except Exception as e:
            print(f"âš ï¸ LLM analysis failed: {e}")
            return self._fallback_keyword_analysis(question)

    def _fallback_keyword_analysis(self, question: str) -> Dict[str, Any]:
        """Fallback keyword-based analysis khi LLM khÃ´ng kháº£ dá»¥ng"""
        question_norm = self._normalize_text(question.lower())
        
        # Check if industrial query
        industrial_keywords = [
            "kcn", "ccn", "khu cong nghiep", "cum cong nghiep",
            "khu cn", "cum cn", "khu nghiep", "cum nghiep"
        ]
        is_industrial = any(k in question_norm for k in industrial_keywords)
        
        if not is_industrial:
            return {
                "is_industrial_query": False,
                "search_type": "province",
                "province": None,
                "specific_name": None,
                "query_type": None,
                "confidence": 0.9,
                "reasoning": "KhÃ´ng pháº£i cÃ¢u há»i vá» khu/cá»¥m cÃ´ng nghiá»‡p"
            }
        
        # Extract province first (improved with TP.HCM recognition)
        province = None
        specific_name = None
        search_type = "province"
        
        if self.df is not None and self.columns_map["province"] is not None:
            unique_provinces = self.df[self.columns_map["province"]].dropna().unique()
            
            # Special handling for TP.HCM variations
            hcm_variations = [
                "thanh pho ho chi minh", "tp ho chi minh", "tp.hcm", "tphcm", 
                "ho chi minh", "hcm", "sai gon", "saigon"
            ]
            
            # Check for TP.HCM variations first
            for hcm_var in hcm_variations:
                if hcm_var in question_norm:
                    # Find the actual province name in data
                    for prov in unique_provinces:
                        prov_norm = self._normalize_text(str(prov).lower())
                        if "ho chi minh" in prov_norm or "hcm" in prov_norm:
                            province = str(prov)
                            break
                    if province:
                        break
            
            # If not TP.HCM, check other provinces
            if not province:
                for prov in unique_provinces:
                    prov_norm = self._normalize_text(str(prov).lower())
                    if prov_norm in question_norm:
                        province = str(prov)
                        break
        
        # Determine search type based on patterns
        # Check for location indicators (province search)
        location_indicators = ["o ", "tai ", "trong ", "tinh ", "thanh pho ", "danh sach"]
        has_location_indicator = any(indicator in question_norm for indicator in location_indicators)
        
        # Check for specific name indicators
        specific_indicators = ["thong tin ve", "cho toi thong tin", "chi tiet ve", "ve khu cong nghiep", "ve cum cong nghiep"]
        has_specific_indicator = any(indicator in question_norm for indicator in specific_indicators)
        
        # Decision logic: prioritize province search if we found a province OR have location indicators
        if province or has_location_indicator:
            search_type = "province"
            specific_name = None
        elif has_specific_indicator:
            search_type = "specific_name"
            # Try to extract the specific name (simplified)
            if "khu cong nghiep" in question_norm:
                # Find text after "khu cong nghiep"
                parts = question_norm.split("khu cong nghiep")
                if len(parts) > 1:
                    specific_name = f"khu cong nghiep{parts[1]}".strip()
            elif "cum cong nghiep" in question_norm:
                # Find text after "cum cong nghiep"
                parts = question_norm.split("cum cong nghiep")
                if len(parts) > 1:
                    specific_name = f"cum cong nghiep{parts[1]}".strip()
        
        # Detect type (simplified) - Cáº¢I THIá»†N LOGIC
        has_cum = any(k in question_norm for k in ["cum", "ccn"])
        has_khu = any(k in question_norm for k in ["khu", "kcn"])
        
        # QUAN TRá»ŒNG: Chá»‰ tráº£ vá» loáº¡i cá»¥ thá»ƒ khi chá»‰ cÃ³ 1 loáº¡i
        if has_cum and has_khu:
            query_type = None  # CÃ³ cáº£ hai
        elif has_cum and not has_khu:
            query_type = "CCN"  # Chá»‰ cÃ³ cá»¥m
        elif has_khu and not has_cum:
            query_type = "KCN"  # Chá»‰ cÃ³ khu
        else:
            query_type = None  # KhÃ´ng rÃµ rÃ ng
        
        return {
            "is_industrial_query": True,
            "search_type": search_type,
            "province": province,
            "specific_name": specific_name,
            "query_type": query_type,
            "confidence": 0.7,
            "reasoning": "Fallback keyword analysis"
        }

    def _generate_smart_error_message(self, question: str, extracted_province: Optional[str]) -> str:
        """Táº¡o thÃ´ng bÃ¡o lá»—i thÃ´ng minh khi khÃ´ng tÃ¬m tháº¥y tá»‰nh"""
        if not self.llm or self.df is None:
            return "â“ Báº¡n vui lÃ²ng nÃªu rÃµ tá»‰nh/thÃ nh phá»‘ cáº§n tra cá»©u."
        
        available_provinces = self.df[self.columns_map["province"]].dropna().unique().tolist()
        available_provinces_str = ", ".join(available_provinces)
        
        prompt = f"""
Báº¡n lÃ  trá»£ lÃ½ thÃ´ng minh vá» dá»¯ liá»‡u khu cÃ´ng nghiá»‡p Viá»‡t Nam.

DANH SÃCH Tá»ˆNH/THÃ€NH PHá» CÃ“ Dá»® LIá»†U:
{available_provinces_str}

CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: "{question}"
Tá»ˆNH ÄÆ¯á»¢C TRÃCH XUáº¤T: "{extracted_province}"

NHIá»†M Vá»¤: Táº¡o thÃ´ng bÃ¡o lá»—i thÃ´ng minh vÃ  há»¯u Ã­ch:
1. ThÃ´ng bÃ¡o tá»‰nh khÃ´ng cÃ³ dá»¯ liá»‡u (náº¿u cÃ³ tá»‰nh Ä‘Æ°á»£c trÃ­ch xuáº¥t)
2. Gá»£i Ã½ 2-3 tá»‰nh gáº§n nháº¥t hoáº·c tÆ°Æ¡ng tá»± cÃ³ dá»¯ liá»‡u
3. Giáº£i thÃ­ch ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t

Náº¿u khÃ´ng trÃ­ch xuáº¥t Ä‘Æ°á»£c tá»‰nh nÃ o, chá»‰ cáº§n nÃ³i "â“ Báº¡n vui lÃ²ng nÃªu rÃµ tá»‰nh/thÃ nh phá»‘ cáº§n tra cá»©u."

CHá»ˆ TRáº¢ Vá»€ THÃ”NG BÃO Báº°NG TIáº¾NG VIá»†T:
"""

        try:
            from langchain_core.messages import HumanMessage
            response = self.llm.invoke([HumanMessage(content=prompt)]).content.strip()
            return response
        except Exception as e:
            print(f"âš ï¸ Error message generation failed: {e}")
            if extracted_province:
                return f"âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u cho '{extracted_province}'. Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn tá»‰nh."
            else:
                return "â“ Báº¡n vui lÃ²ng nÃªu rÃµ tá»‰nh/thÃ nh phá»‘ cáº§n tra cá»©u."

    # ==========================================================
    # ğŸ§  NHáº¬N DIá»†N CÃ‚U Há»I NGÆ¯á»œI DÃ™NG
    # ==========================================================
    def is_count_query(self, question: str) -> bool:
        """
        Nháº­n diá»‡n cÃ¢u há»i vá» tra cá»©u KCN/CCN (Ä‘áº¿m, liá»‡t kÃª, danh sÃ¡ch...).

        NOTE: báº£n cÅ© kiá»ƒm tra count_keywords nhÆ°ng cuá»‘i cÃ¹ng váº«n return has_industrial.
        á» Ä‘Ã¢y giá»¯ â€œthoÃ¡ngâ€ nhÆ°ng há»£p lÃ½ hÆ¡n: cáº§n cÃ³ industrial keyword.
        """
        analysis = self._analyze_query_with_llm(question)
        return analysis.get("is_industrial_query", False)

    # ==========================================================
    # ğŸ§­ XÃC Äá»ŠNH LOáº I TRUY Váº¤N (KHU / Cá»¤M / Cáº¢ HAI)
    # ==========================================================
    def detect_type(self, question: str) -> Optional[str]:
        """
        XÃ¡c Ä‘á»‹nh ngÆ°á»i dÃ¹ng há»i khu hay cá»¥m cÃ´ng nghiá»‡p hoáº·c cáº£ hai sá»­ dá»¥ng LLM analysis.
        """
        analysis = self._analyze_query_with_llm(question)
        return analysis.get("query_type")

    # ==========================================================
    # ğŸ¤– KIá»‚M TRA Tá»ˆNH THÃ”NG MINH Vá»šI LLM
    # ==========================================================
    def _smart_province_check(self, question: str, extracted_province: Optional[str]) -> Tuple[bool, str]:
        """
        Sá»­ dá»¥ng LLM Ä‘á»ƒ kiá»ƒm tra tá»‰nh cÃ³ tá»“n táº¡i trong dá»¯ liá»‡u hay khÃ´ng
        vÃ  Ä‘Æ°a ra pháº£n há»“i thÃ´ng minh
        
        Returns:
            (is_valid: bool, message: str)
        """
        if extracted_province is None:
            return False, "â“ Báº¡n vui lÃ²ng nÃªu rÃµ tá»‰nh/thÃ nh phá»‘ cáº§n tra cá»©u."
            
        if self.df is None:
            return False, "âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ tra cá»©u."
        
        # Láº¥y danh sÃ¡ch tá»‰nh cÃ³ trong dá»¯ liá»‡u
        available_provinces = self.df[self.columns_map["province"]].dropna().unique().tolist()
        
        # Kiá»ƒm tra exact match trÆ°á»›c
        province_normalized = self._normalize_text(extracted_province.lower())
        for available_province in available_provinces:
            if self._normalize_text(available_province.lower()) == province_normalized:
                return True, ""
        
        # Kiá»ƒm tra partial match
        for available_province in available_provinces:
            available_normalized = self._normalize_text(available_province.lower())
            if province_normalized in available_normalized or available_normalized in province_normalized:
                return True, ""
        
        # Náº¿u khÃ´ng cÃ³ LLM, sá»­ dá»¥ng logic fallback Ä‘Æ¡n giáº£n
        if not self.llm:
            # TÃ¬m tá»‰nh gáº§n nháº¥t
            similar_provinces = []
            for available_province in available_provinces:
                available_normalized = self._normalize_text(available_province.lower())
                # Kiá»ƒm tra cÃ³ tá»« chung khÃ´ng
                province_words = set(province_normalized.split())
                available_words = set(available_normalized.split())
                if province_words.intersection(available_words):
                    similar_provinces.append(available_province)
            
            if similar_provinces:
                suggestion = f"CÃ³ thá»ƒ báº¡n muá»‘n tÃ¬m: {', '.join(similar_provinces[:3])}"
            else:
                # Gá»£i Ã½ má»™t sá»‘ tá»‰nh phá»• biáº¿n
                popular_provinces = [p for p in available_provinces if any(keyword in self._normalize_text(p.lower()) 
                                   for keyword in ['ha noi', 'ho chi minh', 'da nang', 'binh duong', 'dong nai'])][:3]
                if popular_provinces:
                    suggestion = f"Má»™t sá»‘ tá»‰nh cÃ³ dá»¯ liá»‡u: {', '.join(popular_provinces)}"
                else:
                    suggestion = f"Má»™t sá»‘ tá»‰nh cÃ³ dá»¯ liá»‡u: {', '.join(available_provinces[:3])}"
            
            return False, f"âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u cho '{extracted_province}'. {suggestion}."
        
        # Sá»­ dá»¥ng LLM náº¿u cÃ³
        available_provinces_str = ", ".join(available_provinces)
        
        prompt = f"""
Báº¡n lÃ  trá»£ lÃ½ thÃ´ng minh vá» dá»¯ liá»‡u khu cÃ´ng nghiá»‡p Viá»‡t Nam.

DANH SÃCH Tá»ˆNH/THÃ€NH PHá» CÃ“ Dá»® LIá»†U:
{available_provinces_str}

CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: "{question}"
Tá»ˆNH ÄÆ¯á»¢C TRÃCH XUáº¤T: "{extracted_province}"

NHIá»†M Vá»¤:
1. Kiá»ƒm tra tá»‰nh Ä‘Æ°á»£c trÃ­ch xuáº¥t cÃ³ trong danh sÃ¡ch khÃ´ng
2. Náº¿u KHÃ”NG cÃ³, Ä‘Æ°a ra pháº£n há»“i thÃ´ng minh:
   - ThÃ´ng bÃ¡o tá»‰nh khÃ´ng cÃ³ dá»¯ liá»‡u
   - Gá»£i Ã½ 2-3 tá»‰nh gáº§n nháº¥t hoáº·c tÆ°Æ¡ng tá»± cÃ³ dá»¯ liá»‡u
   - Giáº£i thÃ­ch ngáº¯n gá»n

Äá»ŠNH Dáº NG PHáº¢N Há»’I:
- Náº¿u tá»‰nh CÃ“ trong danh sÃ¡ch: tráº£ vá» "VALID"
- Náº¿u tá»‰nh KHÃ”NG cÃ³: tráº£ vá» thÃ´ng bÃ¡o chi tiáº¿t báº±ng tiáº¿ng Viá»‡t

CHá»ˆ TRáº¢ Vá»€ Má»˜T TRONG HAI:
- "VALID" (náº¿u tá»‰nh cÃ³ dá»¯ liá»‡u)
- ThÃ´ng bÃ¡o chi tiáº¿t (náº¿u tá»‰nh khÃ´ng cÃ³ dá»¯ liá»‡u)
"""

        try:
            from langchain_core.messages import HumanMessage
            response = self.llm.invoke([HumanMessage(content=prompt)]).content.strip()
            
            if response == "VALID":
                return True, ""
            else:
                return False, response
                
        except Exception as e:
            print(f"âš ï¸ LLM check failed: {e}")
            # Fallback vá» logic Ä‘Æ¡n giáº£n Ä‘Ã£ viáº¿t á»Ÿ trÃªn
            similar_provinces = []
            for available_province in available_provinces:
                available_normalized = self._normalize_text(available_province.lower())
                province_words = set(province_normalized.split())
                available_words = set(available_normalized.split())
                if province_words.intersection(available_words):
                    similar_provinces.append(available_province)
            
            if similar_provinces:
                suggestion = f"CÃ³ thá»ƒ báº¡n muá»‘n tÃ¬m: {', '.join(similar_provinces[:3])}"
            else:
                popular_provinces = [p for p in available_provinces if any(keyword in self._normalize_text(p.lower()) 
                               for keyword in ['ha noi', 'ho chi minh', 'da nang', 'binh duong', 'dong nai'])][:3]
                if popular_provinces:
                    suggestion = f"Má»™t sá»‘ tá»‰nh cÃ³ dá»¯ liá»‡u: {', '.join(popular_provinces)}"
                else:
                    suggestion = f"Má»™t sá»‘ tá»‰nh cÃ³ dá»¯ liá»‡u: {', '.join(available_provinces[:3])}"
            
            return False, f"âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u cho '{extracted_province}'. {suggestion}."

    # ==========================================================
    # ğŸ§© TRÃCH XUáº¤T Tá»ˆNH/THÃ€NH PHá» - Cáº¢I THIá»†N
    # ==========================================================
    def extract_province(self, question: str) -> Optional[str]:
        """TrÃ­ch xuáº¥t tÃªn tá»‰nh/thÃ nh phá»‘ tá»« cÃ¢u há»i sá»­ dá»¥ng LLM analysis."""
        analysis = self._analyze_query_with_llm(question)
        return analysis.get("province")

    # ==========================================================
    # ğŸ”¡ CHUáº¨N HÃ“A TEXT (Bá» Dáº¤U)
    # ==========================================================
    def _normalize_text(self, text: str) -> str:
        intab = "Ã Ã¡áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»©á»«á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘"
        outtab = "aaaaaaaaaaaaaaaaaeeeeeeeeeeeiiiiiooooooooooooooooouuuuuuuuuuuyyyyyd"
        intab_upper = "Ã€Ãáº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬ÃˆÃ‰áººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†ÃŒÃá»ˆÄ¨á»ŠÃ’Ã“á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢Ã™Ãšá»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°á»²Ãá»¶á»¸á»´Ä"
        outtab_upper = "AAAAAAAAAAAAAAAAAEEEEEEEEEEEIIIIIOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYD"
        transtab = str.maketrans(intab + intab_upper, outtab + outtab_upper)
        return str(text).translate(transtab).lower().strip()

    # ==========================================================
    # ğŸ” TRUY Váº¤N Dá»® LIá»†U
    # ==========================================================
    def query_by_province(self, province_name: str, query_type: Optional[str]) -> Optional[pd.DataFrame]:
        """
        Lá»c dá»¯ liá»‡u theo tá»‰nh/thÃ nh phá»‘ vÃ  loáº¡i (KCN/CCN).
        Sá»­ dá»¥ng cá»™t "Loáº¡i" cÃ³ sáºµn trong Excel Ä‘á»ƒ lá»c chÃ­nh xÃ¡c.
        """
        if self.df is None or self.columns_map["province"] is None:
            return None

        # Lá»c theo tá»‰nh/thÃ nh phá»‘
        if province_name == "TOÃ€N QUá»C":
            df_filtered = self.df.copy()
        else:
            df_filtered = self.df[
                self.df[self.columns_map["province"]].astype(str).str.lower().str.contains(
                    str(province_name).lower(), na=False
                )
            ].copy()

        # Lá»c theo loáº¡i KCN/CCN dá»±a vÃ o cá»™t "Loáº¡i"
        if query_type and self.columns_map["type"] is not None:
            df_filtered = df_filtered[
                df_filtered[self.columns_map["type"]].astype(str).str.strip().str.upper() == query_type
            ]

        return df_filtered

    def query_by_specific_name(self, specific_name: str, query_type: Optional[str]) -> Optional[pd.DataFrame]:
        """
        TÃ¬m kiáº¿m KCN/CCN theo tÃªn cá»¥ thá»ƒ.
        Sá»­ dá»¥ng fuzzy matching Ä‘á»ƒ tÃ¬m tÃªn gáº§n nháº¥t.
        """
        if self.df is None or self.columns_map["name"] is None:
            return None

        specific_name_norm = self._normalize_text(specific_name.lower())
        
        # Lá»c theo loáº¡i KCN/CCN trÆ°á»›c náº¿u cÃ³
        df_to_search = self.df.copy()
        if query_type and self.columns_map["type"] is not None:
            df_to_search = df_to_search[
                df_to_search[self.columns_map["type"]].astype(str).str.strip().str.upper() == query_type
            ]

        # TÃ¬m kiáº¿m exact match trÆ°á»›c
        exact_matches = df_to_search[
            df_to_search[self.columns_map["name"]].astype(str).apply(
                lambda x: self._normalize_text(x.lower()) == specific_name_norm
            )
        ]
        
        if not exact_matches.empty:
            return exact_matches

        # TÃ¬m kiáº¿m partial match (contains)
        partial_matches = df_to_search[
            df_to_search[self.columns_map["name"]].astype(str).apply(
                lambda x: specific_name_norm in self._normalize_text(x.lower()) or 
                         self._normalize_text(x.lower()) in specific_name_norm
            )
        ]
        
        if not partial_matches.empty:
            return partial_matches

        # Sá»­ dá»¥ng fuzzy matching náº¿u cÃ³ rapidfuzz
        if process is not None and fuzz is not None:
            all_names = df_to_search[self.columns_map["name"]].astype(str).tolist()
            if all_names:
                # TÃ¬m tÃªn gáº§n nháº¥t
                result = process.extractOne(specific_name, all_names, scorer=fuzz.WRatio)
                if result and result[1] >= 70:  # Threshold 70% cho tÃªn KCN/CCN
                    best_match = result[0]
                    fuzzy_matches = df_to_search[
                        df_to_search[self.columns_map["name"]].astype(str) == best_match
                    ]
                    return fuzzy_matches

        # KhÃ´ng tÃ¬m tháº¥y
        return pd.DataFrame()

    # ==========================================================
    # ğŸ§­ MATCH Tá»ŒA Äá»˜ THEO TÃŠN KCN/CCN
    # ==========================================================
    def _match_coordinates(self, zone_name: str) -> Optional[List[float]]:
        """
        Tráº£ vá» [lng, lat] náº¿u match Ä‘Æ°á»£c tÃªn zone trong GeoJSON.
        """
        if not zone_name:
            return None
        if not self._iz_name_to_coord:
            return None

        z_norm = self._normalize_text(zone_name)

        # 1) exact match normalized
        if z_norm in self._iz_name_to_coord:
            return self._iz_name_to_coord[z_norm]

        # 2) fuzzy match náº¿u cÃ³ rapidfuzz
        if process is not None and fuzz is not None and self._iz_names_original:
            result = process.extractOne(zone_name, self._iz_names_original, scorer=fuzz.WRatio)
            if result and result[1] >= self.match_threshold:
                best_name = result[0]
                best_norm = self._normalize_text(best_name)
                return self._iz_name_to_coord.get(best_norm)

        # 3) fallback: contains match normalized (thÃ´)
        for n, coord in self._iz_name_to_coord.items():
            if n and (n in z_norm or z_norm in n):
                return coord

        return None

    # ==========================================================
    # ğŸ§¾ TRáº¢ Káº¾T QUáº¢ Dáº NG JSON (dict hoáº·c string)
    # ==========================================================
    def format_json_response(
        self,
        df: pd.DataFrame,
        province_name: str,
        query_type: Optional[str],
        as_string: bool = True
    ) -> Any:
        """
        Tráº£ káº¿t quáº£ truy váº¥n dáº¡ng JSON.
        - as_string=True: tráº£ vá» chuá»—i JSON
        - as_string=False: tráº£ vá» dict (khuyáº¿n nghá»‹ khi dÃ¹ng trong Flask)
        """
        # Cáº£i thiá»‡n label hiá»ƒn thá»‹
        if query_type == "KCN":
            label = "khu"
        elif query_type == "CCN":
            label = "cá»¥m"
        else:  # query_type is None - táº¥t cáº£
            label = "khu/cá»¥m"

        if df is None or df.empty:
            obj = {
                "province": province_name,
                "type": query_type,
                "count": 0,
                "message": f"KhÃ´ng tÃ¬m tháº¥y {label} cÃ´ng nghiá»‡p táº¡i {province_name}.",
                "data": [],
                "not_found_coordinates": []
            }
            return json.dumps(obj, ensure_ascii=False, indent=2) if as_string else obj

        cols = self.columns_map
        records = []
        not_found = []

        for _, row in df.iterrows():
            name_val = str(row.get(cols["name"], "")).strip()

            coord = self._match_coordinates(name_val)

            item = {
                "Tá»‰nh/ThÃ nh phá»‘": str(row.get(cols["province"], "")),
                "Loáº¡i": str(row.get(cols["type"], "")),
                "TÃªn": name_val,
                "Äá»‹a chá»‰": str(row.get(cols["address"], "")),
                "Thá»i gian váº­n hÃ nh": str(row.get(cols["operation_time"], "")),
                "Tá»•ng diá»‡n tÃ­ch": str(row.get(cols["area"], "")),
                "GiÃ¡ thuÃª Ä‘áº¥t": str(row.get(cols["rental_price"], "")),
                "NgÃ nh nghá»": str(row.get(cols["industry"], "")),
                # âœ… Bá»” SUNG Tá»ŒA Äá»˜
                "coordinates": coord
            }

            if coord is None and name_val:
                not_found.append(name_val)

            records.append(item)

        # Cáº£i thiá»‡n thÃ´ng bÃ¡o káº¿t quáº£
        if query_type is None:  # Táº¥t cáº£ loáº¡i
            # Äáº¿m sá»‘ lÆ°á»£ng tá»«ng loáº¡i
            kcn_count = sum(1 for r in records if r.get("Loáº¡i", "").upper() == "KCN")
            ccn_count = sum(1 for r in records if r.get("Loáº¡i", "").upper() == "CCN")
            
            if kcn_count > 0 and ccn_count > 0:
                message = f"{province_name} cÃ³ {kcn_count} khu cÃ´ng nghiá»‡p vÃ  {ccn_count} cá»¥m cÃ´ng nghiá»‡p."
            elif kcn_count > 0:
                message = f"{province_name} cÃ³ {kcn_count} khu cÃ´ng nghiá»‡p."
            elif ccn_count > 0:
                message = f"{province_name} cÃ³ {ccn_count} cá»¥m cÃ´ng nghiá»‡p."
            else:
                message = f"{province_name} cÃ³ {len(records)} khu/cá»¥m cÃ´ng nghiá»‡p."
        else:
            message = f"{province_name} cÃ³ {len(records)} {label} cÃ´ng nghiá»‡p."

        obj = {
            "province": province_name,
            "type": query_type,
            "count": len(records),
            "message": message,
            "data": records,
            "not_found_coordinates": not_found
        }

        return json.dumps(obj, ensure_ascii=False, indent=2) if as_string else obj

    def format_json_response_for_specific_name(
        self,
        df: pd.DataFrame,
        specific_name: str,
        query_type: Optional[str],
        as_string: bool = True
    ) -> Any:
        """
        Tráº£ káº¿t quáº£ truy váº¥n theo tÃªn cá»¥ thá»ƒ dáº¡ng JSON.
        - as_string=True: tráº£ vá» chuá»—i JSON
        - as_string=False: tráº£ vá» dict (khuyáº¿n nghá»‹ khi dÃ¹ng trong Flask)
        """
        # Cáº£i thiá»‡n label hiá»ƒn thá»‹
        if query_type == "KCN":
            label = "khu"
        elif query_type == "CCN":
            label = "cá»¥m"
        else:  # query_type is None - táº¥t cáº£
            label = "khu/cá»¥m"

        if df is None or df.empty:
            obj = {
                "search_type": "specific_name",
                "specific_name": specific_name,
                "type": query_type,
                "count": 0,
                "message": f"KhÃ´ng tÃ¬m tháº¥y {label} cÃ´ng nghiá»‡p vá»›i tÃªn '{specific_name}'.",
                "data": [],
                "not_found_coordinates": []
            }
            return json.dumps(obj, ensure_ascii=False, indent=2) if as_string else obj

        cols = self.columns_map
        records = []
        not_found = []

        for _, row in df.iterrows():
            name_val = str(row.get(cols["name"], "")).strip()

            coord = self._match_coordinates(name_val)

            item = {
                "Tá»‰nh/ThÃ nh phá»‘": str(row.get(cols["province"], "")),
                "Loáº¡i": str(row.get(cols["type"], "")),
                "TÃªn": name_val,
                "Äá»‹a chá»‰": str(row.get(cols["address"], "")),
                "Thá»i gian váº­n hÃ nh": str(row.get(cols["operation_time"], "")),
                "Tá»•ng diá»‡n tÃ­ch": str(row.get(cols["area"], "")),
                "GiÃ¡ thuÃª Ä‘áº¥t": str(row.get(cols["rental_price"], "")),
                "NgÃ nh nghá»": str(row.get(cols["industry"], "")),
                # âœ… Bá»” SUNG Tá»ŒA Äá»˜
                "coordinates": coord
            }

            if coord is None and name_val:
                not_found.append(name_val)

            records.append(item)

        # Táº¡o thÃ´ng bÃ¡o káº¿t quáº£ cho specific name search
        if len(records) == 1:
            message = f"TÃ¬m tháº¥y thÃ´ng tin vá» '{specific_name}'."
        else:
            message = f"TÃ¬m tháº¥y {len(records)} káº¿t quáº£ phÃ¹ há»£p vá»›i '{specific_name}'."

        obj = {
            "search_type": "specific_name",
            "specific_name": specific_name,
            "type": query_type,
            "count": len(records),
            "message": message,
            "data": records,
            "not_found_coordinates": not_found
        }

        return json.dumps(obj, ensure_ascii=False, indent=2) if as_string else obj

    # ==========================================================
    # âš™ï¸ Xá»¬ LÃ TRUY Váº¤N NGÆ¯á»œI DÃ™NG
    # ==========================================================
    def process_query(self, question: str, return_json: bool = True, enable_rag: bool = False) -> Tuple[bool, Optional[Any]]:
        """
        Xá»­ lÃ½ truy váº¥n vÃ  tráº£ káº¿t quáº£ sá»­ dá»¥ng prompt-based analysis.
        Há»— trá»£ cáº£ tÃ¬m kiáº¿m theo tá»‰nh vÃ  theo tÃªn KCN/CCN cá»¥ thá»ƒ.
        - return_json=True: tráº£ JSON (máº·c Ä‘á»‹nh)
            + tráº£ vá» STRING JSON (Ä‘á»ƒ backward compatible)
        - return_json=False: tráº£ text báº£ng (nhÆ° cÅ©)
        - enable_rag=True: bá»• sung RAG analysis

        Return:
            (handled: bool, response: Optional[str|dict])
        """
        # Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch toÃ n bá»™ cÃ¢u há»i má»™t láº§n
        analysis = self._analyze_query_with_llm(question)
        
        # Kiá»ƒm tra xem cÃ³ pháº£i cÃ¢u há»i vá» KCN/CCN khÃ´ng
        if not analysis.get("is_industrial_query", False):
            return False, None

        search_type = analysis.get("search_type", "province")
        province = analysis.get("province")
        specific_name = analysis.get("specific_name")
        query_type = analysis.get("query_type")
        
        # Xá»­ lÃ½ theo loáº¡i tÃ¬m kiáº¿m
        if search_type == "specific_name":
            # TÃ¬m kiáº¿m theo tÃªn KCN/CCN cá»¥ thá»ƒ
            if specific_name is None:
                error_message = "â“ Vui lÃ²ng cung cáº¥p tÃªn KCN/CCN cá»¥ thá»ƒ cáº§n tÃ¬m kiáº¿m."
                err = {"error": error_message}
                return True, json.dumps(err, ensure_ascii=False) if return_json else error_message
            
            # Truy váº¥n dá»¯ liá»‡u theo tÃªn cá»¥ thá»ƒ
            df_result = self.query_by_specific_name(specific_name, query_type)
            
            if df_result is None or df_result.empty:
                error_message = f"âŒ KhÃ´ng tÃ¬m tháº¥y KCN/CCN vá»›i tÃªn '{specific_name}'. Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn hoáº·c thá»­ tÃ¬m theo tá»‰nh/thÃ nh phá»‘."
                err = {"error": error_message}
                return True, json.dumps(err, ensure_ascii=False) if return_json else error_message
            
            # Tráº£ káº¿t quáº£ cho specific name search
            if return_json:
                result = self.format_json_response_for_specific_name(df_result, specific_name, query_type, as_string=False)
                
                # âœ… THÃŠM RAG ANALYSIS CHO SPECIFIC NAME
                if enable_rag and isinstance(result, dict):
                    rag_analysis = self.enhance_list_with_rag(result, question)
                    if rag_analysis:
                        result["rag_analysis"] = rag_analysis
                        result["has_rag"] = True
                    else:
                        result["has_rag"] = False
                
                return True, json.dumps(result, ensure_ascii=False, indent=2)
            else:
                return True, self.format_table_response_for_specific_name(df_result, specific_name, query_type)
        
        else:
            # TÃ¬m kiáº¿m theo tá»‰nh (logic cÅ©)
            # Kiá»ƒm tra tá»‰nh cÃ³ há»£p lá»‡ khÃ´ng
            if province is None:
                error_message = self._generate_smart_error_message(question, province)
                err = {"error": error_message}
                return True, json.dumps(err, ensure_ascii=False) if return_json else error_message
            
            # Kiá»ƒm tra tá»‰nh cÃ³ trong dá»¯ liá»‡u khÃ´ng
            is_valid, error_message = self._smart_province_check(question, province)
            if not is_valid:
                err = {"error": error_message}
                return True, json.dumps(err, ensure_ascii=False) if return_json else error_message

            # Truy váº¥n dá»¯ liá»‡u theo tá»‰nh
            df_result = self.query_by_province(province, query_type)

            if return_json:
                # âœ… tráº£ dict Ä‘á»ƒ cÃ³ thá»ƒ thÃªm RAG analysis
                result = self.format_json_response(df_result, province, query_type, as_string=False)
                
                # âœ… THÃŠM RAG ANALYSIS CHO PROVINCE QUERY
                if enable_rag and isinstance(result, dict):
                    rag_analysis = self.enhance_list_with_rag(result, question)
                    if rag_analysis:
                        result["rag_analysis"] = rag_analysis
                        result["has_rag"] = True
                    else:
                        result["has_rag"] = False
                
                return True, json.dumps(result, ensure_ascii=False, indent=2)
            else:
                return True, self.format_table_response(df_result, province, query_type)

    # ==========================================================
    # ğŸ§© GIá»® Láº I HÃ€M CÅ¨ (Báº¢NG TEXT)
    # ==========================================================
    def format_table_response(self, df: pd.DataFrame, province_name: str, query_type: Optional[str]) -> str:
        """(Tuá»³ chá»n) Hiá»ƒn thá»‹ káº¿t quáº£ dáº¡ng báº£ng text"""
        # Cáº£i thiá»‡n label hiá»ƒn thá»‹
        if query_type == "KCN":
            label = "khu"
        elif query_type == "CCN":
            label = "cá»¥m"
        else:  # query_type is None - táº¥t cáº£
            label = "khu/cá»¥m"

        if df is None or df.empty:
            return f"KhÃ´ng tÃ¬m tháº¥y {label} cÃ´ng nghiá»‡p táº¡i {province_name}."

        cols = self.columns_map
        
        # Cáº£i thiá»‡n thÃ´ng bÃ¡o káº¿t quáº£ cho text response
        if query_type is None:  # Táº¥t cáº£ loáº¡i
            # Äáº¿m sá»‘ lÆ°á»£ng tá»«ng loáº¡i
            kcn_count = sum(1 for _, row in df.iterrows() if str(row.get(cols["type"], "")).upper() == "KCN")
            ccn_count = sum(1 for _, row in df.iterrows() if str(row.get(cols["type"], "")).upper() == "CCN")
            
            if kcn_count > 0 and ccn_count > 0:
                response = f"ğŸ“Š {province_name} cÃ³ {kcn_count} khu cÃ´ng nghiá»‡p vÃ  {ccn_count} cá»¥m cÃ´ng nghiá»‡p.\n\n"
            elif kcn_count > 0:
                response = f"ğŸ“Š {province_name} cÃ³ {kcn_count} khu cÃ´ng nghiá»‡p.\n\n"
            elif ccn_count > 0:
                response = f"ğŸ“Š {province_name} cÃ³ {ccn_count} cá»¥m cÃ´ng nghiá»‡p.\n\n"
            else:
                response = f"ğŸ“Š {province_name} cÃ³ {len(df)} khu/cá»¥m cÃ´ng nghiá»‡p.\n\n"
        else:
            response = f"ğŸ“Š {province_name} cÃ³ {len(df)} {label} cÃ´ng nghiá»‡p.\n\n"
            
        for _, row in df.iterrows():
            loai = str(row.get(cols['type'], '')).upper()
            ten = row.get(cols['name'], 'KhÃ´ng rÃµ')
            dia_chi = row.get(cols['address'], '')
            response += f"- [{loai}] {ten} ({dia_chi})\n"
        return response

    def format_table_response_for_specific_name(self, df: pd.DataFrame, specific_name: str, query_type: Optional[str]) -> str:
        """(Tuá»³ chá»n) Hiá»ƒn thá»‹ káº¿t quáº£ tÃ¬m kiáº¿m theo tÃªn cá»¥ thá»ƒ dáº¡ng báº£ng text"""
        # Cáº£i thiá»‡n label hiá»ƒn thá»‹
        if query_type == "KCN":
            label = "khu"
        elif query_type == "CCN":
            label = "cá»¥m"
        else:  # query_type is None - táº¥t cáº£
            label = "khu/cá»¥m"

        if df is None or df.empty:
            return f"KhÃ´ng tÃ¬m tháº¥y {label} cÃ´ng nghiá»‡p vá»›i tÃªn '{specific_name}'."

        cols = self.columns_map
        
        # Táº¡o thÃ´ng bÃ¡o káº¿t quáº£ cho specific name search
        if len(df) == 1:
            response = f"ğŸ“Š TÃ¬m tháº¥y thÃ´ng tin vá» '{specific_name}':\n\n"
        else:
            response = f"ğŸ“Š TÃ¬m tháº¥y {len(df)} káº¿t quáº£ phÃ¹ há»£p vá»›i '{specific_name}':\n\n"
            
        for _, row in df.iterrows():
            loai = str(row.get(cols['type'], '')).upper()
            ten = row.get(cols['name'], 'KhÃ´ng rÃµ')
            dia_chi = row.get(cols['address'], '')
            tinh = row.get(cols['province'], '')
            response += f"- [{loai}] {ten} - {tinh} ({dia_chi})\n"
        return response

    # ==========================================================
    # ğŸ†• IMPROVED KCN DETAIL QUERY WITH MULTIPLE CHOICE SUPPORT
    # ==========================================================
    
    def is_kcn_detail_query(self, question: str) -> bool:
        """
        Kiá»ƒm tra xem cÃ¢u há»i cÃ³ pháº£i lÃ  tra cá»©u chi tiáº¿t KCN/CCN khÃ´ng
        """
        question_lower = question.lower().strip()
        
        # Kiá»ƒm tra tá»« khÃ³a "Detail" trÆ°á»›c - Æ°u tiÃªn cao nháº¥t
        if question_lower.startswith('detail '):
            # Náº¿u báº¯t Ä‘áº§u báº±ng "Detail" vÃ  cÃ³ KCN/CCN thÃ¬ cháº¯c cháº¯n lÃ  detail query
            kcn_keywords = ['kcn', 'ccn', 'khu cÃ´ng nghiá»‡p', 'cá»¥m cÃ´ng nghiá»‡p']
            if any(keyword in question_lower for keyword in kcn_keywords):
                print(f"ğŸ¯ Detected Detail query: {question}")
                return True
        
        # Loáº¡i trá»« cÃ¡c query tá»•ng quÃ¡t trÆ°á»›c
        general_keywords = [
            'cÃ¡c khu cÃ´ng nghiá»‡p', 'danh sÃ¡ch', 'táº¥t cáº£', 'nhá»¯ng khu cÃ´ng nghiá»‡p',
            'khu cÃ´ng nghiá»‡p nÃ o', 'cÃ³ bao nhiÃªu', 'sá»‘ lÆ°á»£ng', 'liá»‡t kÃª',
            'á»Ÿ ', ' táº¡i ', ' trong ', 'tá»‰nh ', 'thÃ nh phá»‘'
        ]
        
        # Náº¿u cÃ³ tá»« khÃ³a tá»•ng quÃ¡t, kiá»ƒm tra ká»¹ hÆ¡n
        has_general = any(keyword in question_lower for keyword in general_keywords)
        
        # Keywords chá»‰ tra cá»©u chi tiáº¿t
        detail_keywords = [
            'thÃ´ng tin vá»', 'cho tÃ´i biáº¿t vá»', 'tÃ¬m hiá»ƒu vá»', 'giá»›i thiá»‡u vá»',
            'chi tiáº¿t vá»', 'mÃ´ táº£ vá»', 'á»Ÿ Ä‘Ã¢u', 'náº±m á»Ÿ Ä‘Ã¢u', 'vá»‹ trÃ­',
            'Ä‘á»‹a chá»‰ cá»§a', 'liÃªn há»‡', 'contact', 'detail'
        ]
        
        # Keywords KCN/CCN
        kcn_keywords = [
            'khu cÃ´ng nghiá»‡p', 'kcn', 'cá»¥m cÃ´ng nghiá»‡p', 'ccn',
            'khu cn', 'cá»¥m cn'
        ]
        
        # Kiá»ƒm tra cÃ³ keyword detail vÃ  KCN
        has_detail_keyword = any(keyword in question_lower for keyword in detail_keywords)
        has_kcn_keyword = any(keyword in question_lower for keyword in kcn_keywords)
        
        # Pattern Ä‘áº·c biá»‡t: chá»‰ cÃ³ "KCN/CCN + tÃªn" mÃ  khÃ´ng cÃ³ tá»« tá»•ng quÃ¡t
        # VÃ­ dá»¥: "Khu cÃ´ng nghiá»‡p VSIP", "CCN TÃ¢n BÃ¬nh"
        simple_kcn_patterns = [
            r'^(khu cÃ´ng nghiá»‡p|kcn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*\s*$',
            r'^(cá»¥m cÃ´ng nghiá»‡p|ccn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*\s*$'
        ]
        
        # Kiá»ƒm tra pattern Ä‘Æ¡n giáº£n trÆ°á»›c
        for pattern in simple_kcn_patterns:
            if re.match(pattern, question_lower):
                print(f"ğŸ¯ Detected simple KCN pattern: {question}")
                return True
        
        # Náº¿u cÃ³ tá»« tá»•ng quÃ¡t nhÆ°ng khÃ´ng cÃ³ detail keyword thÃ¬ khÃ´ng pháº£i detail query
        if has_general and not has_detail_keyword:
            return False
        
        # Kiá»ƒm tra cÃ³ tÃªn KCN cá»¥ thá»ƒ (khÃ´ng chá»‰ lÃ  tá»« khÃ³a chung)
        specific_kcn_patterns = [
            r'(khu cÃ´ng nghiá»‡p|kcn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*',
            r'(cá»¥m cÃ´ng nghiá»‡p|ccn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*'
        ]
        
        has_specific_name = False
        for pattern in specific_kcn_patterns:
            matches = re.findall(pattern, question_lower)
            if matches:
                # Kiá»ƒm tra xem cÃ³ pháº£i chá»‰ lÃ  tÃªn tá»‰nh khÃ´ng
                for match in matches:
                    full_match = match[0] + ' ' + match[1] if isinstance(match, tuple) else match
                    # Loáº¡i trá»« náº¿u chá»‰ lÃ  "khu cÃ´ng nghiá»‡p á»Ÿ [tá»‰nh]"
                    if not re.search(r'\s+á»Ÿ\s+', full_match) and len(full_match.split()) >= 3:
                        has_specific_name = True
                        break
        
        # TrÆ°á»ng há»£p Ä‘áº·c biá»‡t: "KCN ABC á»Ÿ Ä‘Ã¢u" - cÃ³ tÃªn cá»¥ thá»ƒ + "á»Ÿ Ä‘Ã¢u"
        location_question_pattern = r'(khu cÃ´ng nghiá»‡p|kcn|ccn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*\s+á»Ÿ\s+Ä‘Ã¢u'
        if re.search(location_question_pattern, question_lower):
            has_specific_name = True
            has_detail_keyword = True
        
        result = (has_detail_keyword and has_kcn_keyword and has_specific_name) or \
                 (has_specific_name and not has_general)
        
        if result:
            print(f"ğŸ¯ Detected KCN detail query: {question}")
        
        return result

    def process_kcn_detail_query_with_multiple_choice(self, question: str) -> Optional[Dict]:
        """
        Xá»­ lÃ½ cÃ¢u há»i tra cá»©u chi tiáº¿t KCN/CCN vá»›i há»— trá»£ multiple choice
        
        Returns:
            - Náº¿u cÃ³ 1 káº¿t quáº£: {"type": "kcn_detail", "kcn_info": {...}, ...}
            - Náº¿u cÃ³ nhiá»u káº¿t quáº£: {"type": "kcn_multiple_choice", "options": [...], ...}
            - Náº¿u khÃ´ng tÃ¬m tháº¥y: {"type": "kcn_detail_not_found", "message": "..."}
        """
        print(f"ğŸ” Processing KCN detail query: {question}")
        
        if not self.is_kcn_detail_query(question):
            print("âŒ Not a KCN detail query")
            return None
        
        # Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t tÃªn KCN
        specific_name = None
        query_type = None
        
        if self.llm:
            print("ğŸ¤– Using LLM for analysis")
            analysis = self._analyze_query_with_llm(question)
            
            if not analysis.get("is_industrial_query", False):
                print("âŒ LLM says not industrial query")
                return None
            
            if analysis.get("search_type") == "specific_name":
                specific_name = analysis.get("specific_name")
                query_type = analysis.get("query_type")
                print(f"ğŸ¯ LLM extracted: {specific_name}, type: {query_type}")
        
        # Fallback: extract name manually when no LLM or LLM failed
        if not specific_name:
            print("ğŸ”§ Using fallback extraction")
            specific_name = self._extract_kcn_name_fallback(question)
            query_type = None  # Let query_by_specific_name handle this
            print(f"ğŸ¯ Fallback extracted: {specific_name}")
        
        if not specific_name:
            print("âŒ Could not extract KCN name")
            return None
        
        # TÃ¬m thÃ´ng tin KCN tá»« structured data
        print(f"ğŸ” Searching for: {specific_name}")
        df_result = self.query_by_specific_name(specific_name, query_type)
        
        if df_result is None or df_result.empty:
            print(f"âŒ No results found for: {specific_name}")
            return {
                "type": "kcn_detail_not_found",
                "message": f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» '{specific_name}'. Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn hoáº·c thá»­ tÃ¬m kiáº¿m vá»›i tá»« khÃ³a khÃ¡c.",
                "query_name": specific_name
            }
        
        print(f"âœ… Found {len(df_result)} results")
        
        # ğŸ†• KIá»‚M TRA NHIá»€U Káº¾T QUáº¢ TRÃ™NG TÃŠN
        if len(df_result) > 1:
            print(f"ğŸ”€ Multiple results found, creating choice list")
            return self._create_multiple_choice_response(df_result, specific_name, query_type)
        
        # Chá»‰ cÃ³ 1 káº¿t quáº£ - tráº£ vá» chi tiáº¿t nhÆ° cÅ©
        return self._create_single_kcn_detail_response(df_result.iloc[0], specific_name, question)

    def _create_single_kcn_detail_response(self, row, specific_name: str, question: str) -> Dict:
        """
        Táº¡o response cho 1 KCN duy nháº¥t
        """
        cols = self.columns_map
        
        kcn_info = {
            "TÃªn": str(row.get(cols["name"], "")),
            "Äá»‹a chá»‰": str(row.get(cols["address"], "")),
            "Tá»‰nh/ThÃ nh phá»‘": str(row.get(cols["province"], "")),
            "Loáº¡i": str(row.get(cols["type"], "")),
            "Tá»•ng diá»‡n tÃ­ch": str(row.get(cols["area"], "")),
            "GiÃ¡ thuÃª Ä‘áº¥t": str(row.get(cols["rental_price"], "")),
            "Thá»i gian váº­n hÃ nh": str(row.get(cols["operation_time"], "")),
            "NgÃ nh nghá»": str(row.get(cols["industry"], "")),
        }
        
        print(f"ğŸ“‹ KCN Info: {kcn_info['TÃªn']}")
        
        # TÃ¬m tá»a Ä‘á»™
        coordinates = self._match_coordinates(kcn_info["TÃªn"])
        print(f"ğŸ“ Coordinates: {coordinates}")
        
        # Enhance vá»›i RAG
        rag_analysis = self._enhance_with_rag(kcn_info, question)
        
        result = {
            "type": "kcn_detail",
            "kcn_info": kcn_info,
            "coordinates": coordinates,
            "zoom_level": 16,  # Zoom ráº¥t gáº§n Ä‘á»ƒ tháº¥y chi tiáº¿t vá»‹ trÃ­
            "matched_name": kcn_info["TÃªn"],
            "query_name": specific_name,
            "message": f"ThÃ´ng tin chi tiáº¿t vá» {kcn_info['TÃªn']}"
        }
        
        # ThÃªm RAG analysis náº¿u cÃ³
        if rag_analysis:
            result["rag_analysis"] = rag_analysis
            result["has_rag"] = True
            print("âœ… Added RAG analysis")
        else:
            result["has_rag"] = False
            print("âš ï¸ No RAG analysis")
        
        print("âœ… KCN detail query processed successfully")
        return result

    def _extract_kcn_name_fallback(self, question: str) -> Optional[str]:
        """
        Fallback method Ä‘á»ƒ trÃ­ch xuáº¥t tÃªn KCN/CCN khi khÃ´ng cÃ³ LLM
        """
        import re
        
        question_clean = question.strip()
        
        # Pattern Ä‘áº·c biá»‡t cho "Detail KCN/CCN [tÃªn]"
        detail_match = re.search(r'detail\s+(kcn|ccn|khu cÃ´ng nghiá»‡p|cá»¥m cÃ´ng nghiá»‡p)\s+(.+?)(?:\s*$|\s*\?)', question_clean, re.IGNORECASE)
        if detail_match:
            kcn_type = detail_match.group(1).lower()
            kcn_name = detail_match.group(2).strip()
            if kcn_type in ['kcn', 'khu cÃ´ng nghiá»‡p']:
                return f"khu cÃ´ng nghiá»‡p {kcn_name}"
            else:
                return f"cá»¥m cÃ´ng nghiá»‡p {kcn_name}"
        
        # Pattern 1: "vá» [tÃªn KCN]"
        match = re.search(r'vá»\s+(.+?)(?:\s*$|\s*\?)', question_clean, re.IGNORECASE)
        if match:
            return match.group(1).strip()
        
        # Pattern 2: Chá»‰ cÃ³ "KCN/CCN + tÃªn" (pattern Ä‘Æ¡n giáº£n)
        simple_patterns = [
            r'^(khu cÃ´ng nghiá»‡p|kcn)\s+(.+?)(?:\s*$|\s*\?)',
            r'^(cá»¥m cÃ´ng nghiá»‡p|ccn)\s+(.+?)(?:\s*$|\s*\?)'
        ]
        
        for pattern in simple_patterns:
            match = re.search(pattern, question_clean, re.IGNORECASE)
            if match:
                kcn_type = match.group(1).lower()
                kcn_name = match.group(2).strip()
                return f"{kcn_type} {kcn_name}"
        
        # Pattern 3: TÃ¬m tÃªn cÃ³ chá»©a KCN/CCN keywords trong cÃ¢u
        kcn_patterns = [
            r'(khu cÃ´ng nghiá»‡p[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)',
            r'(kcn[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)',
            r'(cá»¥m cÃ´ng nghiá»‡p[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)',
            r'(ccn[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)'
        ]
        
        for pattern in kcn_patterns:
            match = re.search(pattern, question_clean, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None

    def _create_multiple_choice_response(self, df_result: pd.DataFrame, specific_name: str, query_type: Optional[str]) -> Dict:
        """
        Táº¡o response khi cÃ³ nhiá»u KCN/CCN trÃ¹ng tÃªn Ä‘á»ƒ ngÆ°á»i dÃ¹ng lá»±a chá»n
        """
        cols = self.columns_map
        options = []
        
        for idx, row in df_result.iterrows():
            kcn_name = str(row.get(cols["name"], ""))
            kcn_province = str(row.get(cols["province"], ""))
            kcn_address = str(row.get(cols["address"], ""))
            kcn_type = str(row.get(cols["type"], ""))
            
            # TÃ¬m tá»a Ä‘á»™ cho tá»«ng option
            coordinates = self._match_coordinates(kcn_name)
            
            option = {
                "id": idx,  # ID Ä‘á»ƒ ngÆ°á»i dÃ¹ng chá»n
                "name": kcn_name,
                "province": kcn_province,
                "address": kcn_address,
                "type": kcn_type,
                "coordinates": coordinates,
                "display_text": f"{kcn_name} - {kcn_province}"
            }
            options.append(option)
        
        # Táº¡o message thÃ´ng bÃ¡o
        if query_type == "KCN":
            type_label = "khu cÃ´ng nghiá»‡p"
        elif query_type == "CCN":
            type_label = "cá»¥m cÃ´ng nghiá»‡p"
        else:
            type_label = "khu/cá»¥m cÃ´ng nghiá»‡p"
        
        message = f"TÃ¬m tháº¥y {len(options)} {type_label} cÃ³ tÃªn tÆ°Æ¡ng tá»± '{specific_name}'. Vui lÃ²ng chá»n má»™t trong cÃ¡c tÃ¹y chá»n sau:"
        
        return {
            "type": "kcn_multiple_choice",  # Thay Ä‘á»•i type Ä‘á»ƒ main.py xá»­ lÃ½
            "options": options,
            "message": message,
            "query_name": specific_name,
            "total_options": len(options)
        }

    def _enhance_with_rag(self, kcn_info: Dict, question: str) -> str:
        """
        Sá»­ dá»¥ng RAG Ä‘á»ƒ bá»• sung thÃ´ng tin chi tiáº¿t vá» KCN (simplified version)
        """
        if not self.llm:
            return ""
        
        try:
            # Táº¡o context tá»« structured data
            kcn_name = kcn_info.get('TÃªn', 'N/A')
            kcn_address = kcn_info.get('Äá»‹a chá»‰', 'N/A')
            kcn_province = kcn_info.get('Tá»‰nh/ThÃ nh phá»‘', 'N/A')
            
            # Táº¡o enhanced query cho RAG
            rag_query = f"HÃ£y cung cáº¥p thÃ´ng tin chi tiáº¿t vá» {kcn_name} táº¡i {kcn_province}. Äá»‹a chá»‰: {kcn_address}"
            
            # Gá»i RAG system
            if hasattr(self.llm, 'invoke'):
                rag_response = self.llm.invoke(rag_query)
                if isinstance(rag_response, str):
                    return rag_response
                elif hasattr(rag_response, 'content'):
                    return rag_response.content
                else:
                    return str(rag_response)
            
            return ""
            
        except Exception as e:
            print(f"âš ï¸ RAG enhancement error: {e}")
            return ""

    def enhance_list_with_rag(self, query_result: Dict, question: str) -> str:
        """
        Sá»­ dá»¥ng RAG Ä‘á»ƒ bá»• sung thÃ´ng tin cho danh sÃ¡ch KCN/CCN
        """
        if not self.llm:
            return ""
        
        try:
            # TrÃ­ch xuáº¥t thÃ´ng tin tá»« query result
            province = query_result.get('province', 'N/A')
            count = query_result.get('count', 0)
            query_type = query_result.get('type', 'N/A')
            
            # Láº¥y tÃªn má»™t sá»‘ KCN/CCN tiÃªu biá»ƒu
            data = query_result.get('data', [])
            sample_names = [item.get('TÃªn', '') for item in data[:5]]
            sample_names_str = ', '.join(sample_names) if sample_names else 'N/A'
            
            # Táº¡o context-aware RAG query
            if query_type == "KCN":
                type_label = "khu cÃ´ng nghiá»‡p"
            elif query_type == "CCN":
                type_label = "cá»¥m cÃ´ng nghiá»‡p"
            else:
                type_label = "khu vÃ  cá»¥m cÃ´ng nghiá»‡p"
            
            rag_query = f"""
PhÃ¢n tÃ­ch tÃ¬nh hÃ¬nh {type_label} táº¡i tá»‰nh {province}.

Dá»¯ liá»‡u hiá»ƒn thá»‹ {count} {type_label}, bao gá»“m: {sample_names_str}

HÃ£y cung cáº¥p thÃ´ng tin chi tiáº¿t vá»:
1. Tá»•ng quan vá» tÃ¬nh hÃ¬nh phÃ¡t triá»ƒn {type_label} táº¡i {province}
2. ChÃ­nh sÃ¡ch Æ°u Ä‘Ã£i Ä‘áº§u tÆ° vÃ  thu hÃºt FDI cá»§a tá»‰nh
3. NgÃ nh nghá» trá»ng Ä‘iá»ƒm vÃ  lá»£i tháº¿ cáº¡nh tranh
4. Háº¡ táº§ng giao thÃ´ng, logistics vÃ  káº¿t ná»‘i vÃ¹ng
5. Cháº¥t lÆ°á»£ng nguá»“n nhÃ¢n lá»±c vÃ  Ä‘Ã o táº¡o
6. MÃ´i trÆ°á»ng Ä‘áº§u tÆ° vÃ  thá»§ tá»¥c hÃ nh chÃ­nh
7. Káº¿ hoáº¡ch phÃ¡t triá»ƒn trong 5-10 nÄƒm tá»›i
8. So sÃ¡nh vá»›i cÃ¡c tá»‰nh lÃ¢n cáº­n trong khu vá»±c

CÃ¢u há»i gá»‘c cá»§a ngÆ°á»i dÃ¹ng: "{question}"

HÃ£y tráº£ lá»i má»™t cÃ¡ch chi tiáº¿t vÃ  thá»±c táº¿, táº­p trung vÃ o thÃ´ng tin há»¯u Ã­ch cho nhÃ  Ä‘áº§u tÆ°.
"""
            
            # Gá»i RAG system
            if hasattr(self.llm, 'invoke'):
                rag_response = self.llm.invoke(rag_query)
                if isinstance(rag_response, str):
                    return rag_response
                elif hasattr(rag_response, 'content'):
                    return rag_response.content
                else:
                    return str(rag_response)
            
            return ""
            
        except Exception as e:
            print(f"âš ï¸ List RAG enhancement error: {e}")
            return ""

    def enhance_chart_with_rag(self, chart_data: Dict, question: str) -> str:
        """
        Sá»­ dá»¥ng RAG Ä‘á»ƒ bá»• sung phÃ¢n tÃ­ch cho biá»ƒu Ä‘á»“
        """
        if not self.llm:
            return ""
        
        try:
            # TrÃ­ch xuáº¥t thÃ´ng tin tá»« chart data
            province = chart_data.get('province', 'N/A')
            chart_type = chart_data.get('chart_type', 'N/A')
            data_count = len(chart_data.get('data', []))
            
            # Táº¡o context-aware RAG query
            rag_query = f"""
PhÃ¢n tÃ­ch biá»ƒu Ä‘á»“ {chart_type} vá» khu cÃ´ng nghiá»‡p táº¡i {province}.

Dá»¯ liá»‡u hiá»ƒn thá»‹ {data_count} khu cÃ´ng nghiá»‡p.

HÃ£y cung cáº¥p phÃ¢n tÃ­ch chi tiáº¿t vá»:
1. TÃ¬nh hÃ¬nh phÃ¡t triá»ƒn khu cÃ´ng nghiá»‡p táº¡i {province}
2. ChÃ­nh sÃ¡ch Æ°u Ä‘Ã£i Ä‘áº§u tÆ° cá»§a tá»‰nh
3. NgÃ nh nghá» trá»ng Ä‘iá»ƒm vÃ  tiá»m nÄƒng
4. Háº¡ táº§ng giao thÃ´ng vÃ  logistics
5. So sÃ¡nh vá»›i cÃ¡c tá»‰nh lÃ¢n cáº­n
6. Xu hÆ°á»›ng phÃ¡t triá»ƒn trong tÆ°Æ¡ng lai
7. PhÃ¢n tÃ­ch dá»¯ liá»‡u tá»« biá»ƒu Ä‘á»“ vÃ  Ä‘Æ°a ra nháº­n xÃ©t

CÃ¢u há»i gá»‘c cá»§a ngÆ°á»i dÃ¹ng: "{question}"

HÃ£y tráº£ lá»i má»™t cÃ¡ch chi tiáº¿t, táº­p trung vÃ o phÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  cÆ¡ há»™i Ä‘áº§u tÆ°.
"""
            
            # Gá»i RAG system
            if hasattr(self.llm, 'invoke'):
                rag_response = self.llm.invoke(rag_query)
                if isinstance(rag_response, str):
                    return rag_response
                elif hasattr(rag_response, 'content'):
                    return rag_response.content
                else:
                    return str(rag_response)
            
            return ""
            
        except Exception as e:
            print(f"âš ï¸ Chart RAG enhancement error: {e}")
            return ""


# ==========================================================
# ğŸ”Œ TÃCH Há»¢P VÃ€O CHATBOT
# ==========================================================
def integrate_excel_to_chatbot(excel_path: str, geojson_path: Optional[str] = None, llm=None):
    """TÃ­ch há»£p module Excel vÃ o chatbot"""
    if not Path(excel_path).exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file Excel: {excel_path}")
        return None
    handler = ExcelQueryHandler(excel_path, geojson_path=geojson_path, llm=llm)
    print("âœ… ÄÃ£ tÃ­ch há»£p module truy váº¥n Excel vá»›i LLM support.")
    return handler


# ==========================================================
# ğŸ§ª TEST MODULE
# ==========================================================
if __name__ == "__main__":
    EXCEL_FILE = r"./data/IIPMap_FULL_63_COMPLETE.xlsx"
    GEOJSON_FILE = r"./map_ui/industrial_zones.geojson"  

    # Khá»Ÿi táº¡o LLM cho test
    try:
        from langchain_openai import ChatOpenAI
        test_llm = ChatOpenAI(
            model_name="gpt-4o-mini",
            temperature=0
        )
        print("âœ… LLM initialized for testing")
    except:
        test_llm = None
        print("âš ï¸ LLM not available for testing")

    handler = ExcelQueryHandler(EXCEL_FILE, geojson_path=GEOJSON_FILE, llm=test_llm)

    test_queries = [
        "Danh sÃ¡ch cá»¥m cÃ´ng nghiá»‡p á»Ÿ Báº¯c Ninh",
        "Danh sÃ¡ch khu cÃ´ng nghiá»‡p á»Ÿ Báº¯c Ninh",
        "Danh sÃ¡ch khu vÃ  cá»¥m cÃ´ng nghiá»‡p á»Ÿ Báº¯c Ninh",
        "Danh sÃ¡ch táº¥t cáº£ khu cÃ´ng nghiá»‡p vÃ  cá»¥m cÃ´ng nghiá»‡p á»Ÿ HÃ  Ná»™i",
        "Váº½ biá»ƒu Ä‘á»“ cá»™t vá» diá»‡n tÃ­ch cá»§a khu cÃ´ng nghiá»‡p á»Ÿ Há»“ ChÃ­ Minh",
        "Váº½ biá»ƒu Ä‘á»“ cá»™t vá» diá»‡n tÃ­ch cá»§a cá»¥m cÃ´ng nghiá»‡p á»Ÿ ÄÃ  Náºµng",
        "Váº½ biá»ƒu Ä‘á»“ cá»™t vá» diá»‡n tÃ­ch cá»§a cáº£ khu vÃ  cá»¥m cÃ´ng nghiá»‡p á»Ÿ BÃ¬nh DÆ°Æ¡ng",
        "Khu vÃ  cá»¥m cÃ´ng nghiá»‡p tá»‰nh Lai ChÃ¢u",  # Test tá»‰nh khÃ´ng cÃ³ dá»¯ liá»‡u
        "Danh sÃ¡ch khu cÃ´ng nghiá»‡p á»Ÿ Äiá»‡n BiÃªn",  # Test tá»‰nh khÃ´ng cÃ³ dá»¯ liá»‡u
        # Test specific name searches
        "cho tÃ´i thÃ´ng tin vá» KHU CÃ”NG NGHIá»†P NGÅ¨ Láº C - VÄ¨NH LONG",
        "thÃ´ng tin vá» khu cÃ´ng nghiá»‡p SÃ³ng Tháº§n",
        "tÃ¬m cá»¥m cÃ´ng nghiá»‡p TÃ¢n BÃ¬nh",
        "KHU CÃ”NG NGHIá»†P VSIP Báº®C NINH",
        "cá»¥m cÃ´ng nghiá»‡p PhÃº Má»¹"
    ]

    print("\n" + "=" * 80)
    print("TEST MODULE TRáº¢ Káº¾T QUáº¢ Dáº NG JSON (CÃ“ Tá»ŒA Äá»˜ + LLM SMART CHECK)")
    print("=" * 80)

    for query in test_queries:
        print(f"\nâ“ {query}")
        handled, response = handler.process_query(query, return_json=True)
        if handled:
            print(response)
        else:
            print("â­ï¸ Bá» qua - KhÃ´ng pháº£i cÃ¢u há»i liá»‡t kÃª KCN/CCN hoáº·c thiáº¿u thÃ´ng tin")
        print("-" * 80)

    # ==========================================================
    # ğŸ†• MULTIPLE CHOICE SUPPORT FOR KCN DETAIL QUERIES
    # ==========================================================
    
    def _create_multiple_choice_response(self, df_result: pd.DataFrame, specific_name: str, query_type: Optional[str]) -> Dict:
        """
        Táº¡o response khi cÃ³ nhiá»u KCN/CCN trÃ¹ng tÃªn Ä‘á»ƒ ngÆ°á»i dÃ¹ng lá»±a chá»n
        """
        cols = self.columns_map
        options = []
        
        for idx, row in df_result.iterrows():
            kcn_name = str(row.get(cols["name"], ""))
            kcn_province = str(row.get(cols["province"], ""))
            kcn_address = str(row.get(cols["address"], ""))
            kcn_type = str(row.get(cols["type"], ""))
            
            # TÃ¬m tá»a Ä‘á»™ cho tá»«ng option
            coordinates = self._match_coordinates(kcn_name)
            
            option = {
                "id": idx,  # ID Ä‘á»ƒ ngÆ°á»i dÃ¹ng chá»n
                "name": kcn_name,
                "province": kcn_province,
                "address": kcn_address,
                "type": kcn_type,
                "coordinates": coordinates,
                "display_text": f"{kcn_name} - {kcn_province}"
            }
            options.append(option)
        
        # Táº¡o message thÃ´ng bÃ¡o
        if query_type == "KCN":
            type_label = "khu cÃ´ng nghiá»‡p"
        elif query_type == "CCN":
            type_label = "cá»¥m cÃ´ng nghiá»‡p"
        else:
            type_label = "khu/cá»¥m cÃ´ng nghiá»‡p"
        
        message = f"TÃ¬m tháº¥y {len(options)} {type_label} cÃ³ tÃªn tÆ°Æ¡ng tá»± '{specific_name}'. Vui lÃ²ng chá»n má»™t trong cÃ¡c tÃ¹y chá»n sau:"
        
        return {
            "type": "kcn_multiple_choice",  # Thay Ä‘á»•i type Ä‘á»ƒ main.py xá»­ lÃ½
            "options": options,
            "message": message,
            "query_name": specific_name,
            "total_options": len(options)
        }

    def process_kcn_detail_query(self, question: str) -> Optional[Dict]:
        """
        Xá»­ lÃ½ cÃ¢u há»i tra cá»©u chi tiáº¿t KCN/CCN vá»›i há»— trá»£ multiple choice
        """
        print(f"ğŸ” Processing KCN detail query: {question}")
        
        if not self.is_kcn_detail_query(question):
            print("âŒ Not a KCN detail query")
            return None
        
        # Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t tÃªn KCN
        specific_name = None
        query_type = None
        
        if self.llm:
            print("ğŸ¤– Using LLM for analysis")
            analysis = self._analyze_query_with_llm(question)
            
            if not analysis.get("is_industrial_query", False):
                print("âŒ LLM says not industrial query")
                return None
            
            if analysis.get("search_type") == "specific_name":
                specific_name = analysis.get("specific_name")
                query_type = analysis.get("query_type")
                print(f"ğŸ¯ LLM extracted: {specific_name}, type: {query_type}")
        
        # Fallback: extract name manually when no LLM or LLM failed
        if not specific_name:
            print("ğŸ”§ Using fallback extraction")
            specific_name = self._extract_kcn_name_fallback(question)
            query_type = None  # Let query_by_specific_name handle this
            print(f"ğŸ¯ Fallback extracted: {specific_name}")
        
        if not specific_name:
            print("âŒ Could not extract KCN name")
            return None
        
        # TÃ¬m thÃ´ng tin KCN tá»« structured data
        print(f"ğŸ” Searching for: {specific_name}")
        df_result = self.query_by_specific_name(specific_name, query_type)
        
        if df_result is None or df_result.empty:
            print(f"âŒ No results found for: {specific_name}")
            return {
                "type": "kcn_detail_not_found",
                "message": f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» '{specific_name}'. Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn hoáº·c thá»­ tÃ¬m kiáº¿m vá»›i tá»« khÃ³a khÃ¡c.",
                "query_name": specific_name
            }
        
        print(f"âœ… Found {len(df_result)} results")
        
        # ğŸ†• KIá»‚M TRA NHIá»€U Káº¾T QUáº¢ TRÃ™NG TÃŠN
        if len(df_result) > 1:
            print(f"ğŸ”€ Multiple results found, creating choice list")
            
            # Táº¡o thÃ´ng bÃ¡o vá»›i danh sÃ¡ch lá»±a chá»n trong message
            choice_response = self._create_multiple_choice_response(df_result, specific_name, query_type)
            
            # Format thÃ nh text message Ä‘á»ƒ main.py cÃ³ thá»ƒ hiá»ƒn thá»‹
            options = choice_response.get("options", [])
            message_lines = [choice_response.get("message", "")]
            message_lines.append("")  # DÃ²ng trá»‘ng
            
            for i, option in enumerate(options):
                display_text = option.get("display_text", "N/A")
                message_lines.append(f"{i+1}. {display_text}")
            
            message_lines.append("")
            message_lines.append("Vui lÃ²ng gá»­i sá»‘ thá»© tá»± (vÃ­ dá»¥: '1', '2', '3'...) Ä‘á»ƒ xem thÃ´ng tin chi tiáº¿t.")
            
            full_message = "\n".join(message_lines)
            
            # Tráº£ vá» dáº¡ng text message thay vÃ¬ multiple_choice Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i main.py
            return {
                "type": "kcn_detail_not_found",  # Sá»­ dá»¥ng type nÃ y Ä‘á»ƒ main.py tráº£ vá» text
                "message": full_message,
                "query_name": specific_name,
                # LÆ°u thÃ´ng tin Ä‘á»ƒ xá»­ lÃ½ sau náº¿u cáº§n
                "_multiple_choice_data": choice_response
            }
        
        # Chá»‰ cÃ³ 1 káº¿t quáº£ - xá»­ lÃ½ nhÆ° cÅ©
        first_row = df_result.iloc[0]
        cols = self.columns_map
        
        kcn_info = {
            "TÃªn": str(first_row.get(cols["name"], "")),
            "Äá»‹a chá»‰": str(first_row.get(cols["address"], "")),
            "Tá»‰nh/ThÃ nh phá»‘": str(first_row.get(cols["province"], "")),
            "Loáº¡i": str(first_row.get(cols["type"], "")),
            "Tá»•ng diá»‡n tÃ­ch": str(first_row.get(cols["area"], "")),
            "GiÃ¡ thuÃª Ä‘áº¥t": str(first_row.get(cols["rental_price"], "")),
            "Thá»i gian váº­n hÃ nh": str(first_row.get(cols["operation_time"], "")),
            "NgÃ nh nghá»": str(first_row.get(cols["industry"], "")),
        }
        
        print(f"ğŸ“‹ KCN Info: {kcn_info['TÃªn']}")
        
        # TÃ¬m tá»a Ä‘á»™
        coordinates = self._match_coordinates(kcn_info["TÃªn"])
        print(f"ğŸ“ Coordinates: {coordinates}")
        
        # Enhance vá»›i RAG
        rag_analysis = self._enhance_with_rag(kcn_info, question)
        
        result = {
            "type": "kcn_detail",
            "kcn_info": kcn_info,
            "coordinates": coordinates,
            "zoom_level": 16,  # Zoom ráº¥t gáº§n Ä‘á»ƒ tháº¥y chi tiáº¿t vá»‹ trÃ­
            "matched_name": kcn_info["TÃªn"],
            "query_name": specific_name,
            "message": f"ThÃ´ng tin chi tiáº¿t vá» {kcn_info['TÃªn']}"
        }
        
        # ThÃªm RAG analysis náº¿u cÃ³
        if rag_analysis:
            result["rag_analysis"] = rag_analysis
            result["has_rag"] = True
            print("âœ… Added RAG analysis")
        else:
            result["has_rag"] = False
            print("âš ï¸ No RAG analysis")
        
        print("âœ… KCN detail query processed successfully")
        return result

    def _extract_kcn_name_fallback(self, question: str) -> Optional[str]:
        """
        Fallback method Ä‘á»ƒ trÃ­ch xuáº¥t tÃªn KCN/CCN khi khÃ´ng cÃ³ LLM
        """
        import re
        
        question_clean = question.strip()
        
        # Pattern Ä‘áº·c biá»‡t cho "Detail KCN/CCN [tÃªn]"
        detail_match = re.search(r'detail\s+(kcn|ccn|khu cÃ´ng nghiá»‡p|cá»¥m cÃ´ng nghiá»‡p)\s+(.+?)(?:\s*$|\s*\?)', question_clean, re.IGNORECASE)
        if detail_match:
            kcn_type = detail_match.group(1).lower()
            kcn_name = detail_match.group(2).strip()
            if kcn_type in ['kcn', 'khu cÃ´ng nghiá»‡p']:
                return f"khu cÃ´ng nghiá»‡p {kcn_name}"
            else:
                return f"cá»¥m cÃ´ng nghiá»‡p {kcn_name}"
        
        # Pattern 1: "vá» [tÃªn KCN]"
        match = re.search(r'vá»\s+(.+?)(?:\s*$|\s*\?)', question_clean, re.IGNORECASE)
        if match:
            return match.group(1).strip()
        
        # Pattern 2: Chá»‰ cÃ³ "KCN/CCN + tÃªn" (pattern Ä‘Æ¡n giáº£n)
        simple_patterns = [
            r'^(khu cÃ´ng nghiá»‡p|kcn)\s+(.+?)(?:\s*$|\s*\?)',
            r'^(cá»¥m cÃ´ng nghiá»‡p|ccn)\s+(.+?)(?:\s*$|\s*\?)'
        ]
        
        for pattern in simple_patterns:
            match = re.search(pattern, question_clean, re.IGNORECASE)
            if match:
                kcn_type = match.group(1).lower()
                kcn_name = match.group(2).strip()
                return f"{kcn_type} {kcn_name}"
        
        # Pattern 3: TÃ¬m tÃªn cÃ³ chá»©a KCN/CCN keywords trong cÃ¢u
        kcn_patterns = [
            r'(khu cÃ´ng nghiá»‡p[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)',
            r'(kcn[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)',
            r'(cá»¥m cÃ´ng nghiá»‡p[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)',
            r'(ccn[\w\s\-]+?)(?:\s*$|\s*\?|á»Ÿ|táº¡i)'
        ]
        
        for pattern in kcn_patterns:
            match = re.search(pattern, question_clean, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    # ==========================================================
    # ğŸ†• IMPROVED KCN DETAIL QUERY WITH MULTIPLE CHOICE SUPPORT
    # ==========================================================
    
    def is_kcn_detail_query(self, question: str) -> bool:
        """
        Kiá»ƒm tra xem cÃ¢u há»i cÃ³ pháº£i lÃ  tra cá»©u chi tiáº¿t KCN/CCN khÃ´ng
        """
        question_lower = question.lower().strip()
        
        # Kiá»ƒm tra tá»« khÃ³a "Detail" trÆ°á»›c - Æ°u tiÃªn cao nháº¥t
        if question_lower.startswith('detail '):
            # Náº¿u báº¯t Ä‘áº§u báº±ng "Detail" vÃ  cÃ³ KCN/CCN thÃ¬ cháº¯c cháº¯n lÃ  detail query
            kcn_keywords = ['kcn', 'ccn', 'khu cÃ´ng nghiá»‡p', 'cá»¥m cÃ´ng nghiá»‡p']
            if any(keyword in question_lower for keyword in kcn_keywords):
                print(f"ğŸ¯ Detected Detail query: {question}")
                return True
        
        # Loáº¡i trá»« cÃ¡c query tá»•ng quÃ¡t trÆ°á»›c
        general_keywords = [
            'cÃ¡c khu cÃ´ng nghiá»‡p', 'danh sÃ¡ch', 'táº¥t cáº£', 'nhá»¯ng khu cÃ´ng nghiá»‡p',
            'khu cÃ´ng nghiá»‡p nÃ o', 'cÃ³ bao nhiÃªu', 'sá»‘ lÆ°á»£ng', 'liá»‡t kÃª',
            'á»Ÿ ', ' táº¡i ', ' trong ', 'tá»‰nh ', 'thÃ nh phá»‘'
        ]
        
        # Náº¿u cÃ³ tá»« khÃ³a tá»•ng quÃ¡t, kiá»ƒm tra ká»¹ hÆ¡n
        has_general = any(keyword in question_lower for keyword in general_keywords)
        
        # Keywords chá»‰ tra cá»©u chi tiáº¿t
        detail_keywords = [
            'thÃ´ng tin vá»', 'cho tÃ´i biáº¿t vá»', 'tÃ¬m hiá»ƒu vá»', 'giá»›i thiá»‡u vá»',
            'chi tiáº¿t vá»', 'mÃ´ táº£ vá»', 'á»Ÿ Ä‘Ã¢u', 'náº±m á»Ÿ Ä‘Ã¢u', 'vá»‹ trÃ­',
            'Ä‘á»‹a chá»‰ cá»§a', 'liÃªn há»‡', 'contact', 'detail'
        ]
        
        # Keywords KCN/CCN
        kcn_keywords = [
            'khu cÃ´ng nghiá»‡p', 'kcn', 'cá»¥m cÃ´ng nghiá»‡p', 'ccn',
            'khu cn', 'cá»¥m cn'
        ]
        
        # Kiá»ƒm tra cÃ³ keyword detail vÃ  KCN
        has_detail_keyword = any(keyword in question_lower for keyword in detail_keywords)
        has_kcn_keyword = any(keyword in question_lower for keyword in kcn_keywords)
        
        # Pattern Ä‘áº·c biá»‡t: chá»‰ cÃ³ "KCN/CCN + tÃªn" mÃ  khÃ´ng cÃ³ tá»« tá»•ng quÃ¡t
        # VÃ­ dá»¥: "Khu cÃ´ng nghiá»‡p VSIP", "CCN TÃ¢n BÃ¬nh"
        simple_kcn_patterns = [
            r'^(khu cÃ´ng nghiá»‡p|kcn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*\s*$',
            r'^(cá»¥m cÃ´ng nghiá»‡p|ccn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*\s*$'
        ]
        
        # Kiá»ƒm tra pattern Ä‘Æ¡n giáº£n trÆ°á»›c
        for pattern in simple_kcn_patterns:
            if re.match(pattern, question_lower):
                print(f"ğŸ¯ Detected simple KCN pattern: {question}")
                return True
        
        # Náº¿u cÃ³ tá»« tá»•ng quÃ¡t nhÆ°ng khÃ´ng cÃ³ detail keyword thÃ¬ khÃ´ng pháº£i detail query
        if has_general and not has_detail_keyword:
            return False
        
        # Kiá»ƒm tra cÃ³ tÃªn KCN cá»¥ thá»ƒ (khÃ´ng chá»‰ lÃ  tá»« khÃ³a chung)
        specific_kcn_patterns = [
            r'(khu cÃ´ng nghiá»‡p|kcn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*',
            r'(cá»¥m cÃ´ng nghiá»‡p|ccn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*'
        ]
        
        has_specific_name = False
        for pattern in specific_kcn_patterns:
            matches = re.findall(pattern, question_lower)
            if matches:
                # Kiá»ƒm tra xem cÃ³ pháº£i chá»‰ lÃ  tÃªn tá»‰nh khÃ´ng
                for match in matches:
                    full_match = match[0] + ' ' + match[1] if isinstance(match, tuple) else match
                    # Loáº¡i trá»« náº¿u chá»‰ lÃ  "khu cÃ´ng nghiá»‡p á»Ÿ [tá»‰nh]"
                    if not re.search(r'\s+á»Ÿ\s+', full_match) and len(full_match.split()) >= 3:
                        has_specific_name = True
                        break
        
        # TrÆ°á»ng há»£p Ä‘áº·c biá»‡t: "KCN ABC á»Ÿ Ä‘Ã¢u" - cÃ³ tÃªn cá»¥ thá»ƒ + "á»Ÿ Ä‘Ã¢u"
        location_question_pattern = r'(khu cÃ´ng nghiá»‡p|kcn|ccn)\s+[a-zA-ZÃ€-á»¹0-9]+(?:\s+[a-zA-ZÃ€-á»¹0-9\-]+)*\s+á»Ÿ\s+Ä‘Ã¢u'
        if re.search(location_question_pattern, question_lower):
            has_specific_name = True
            has_detail_keyword = True
        
        result = (has_detail_keyword and has_kcn_keyword and has_specific_name) or \
                 (has_specific_name and not has_general)
        
        if result:
            print(f"ğŸ¯ Detected KCN detail query: {question}")
        
        return result

    def process_kcn_detail_query_with_multiple_choice(self, question: str) -> Optional[Dict]:
        """
        Xá»­ lÃ½ cÃ¢u há»i tra cá»©u chi tiáº¿t KCN/CCN vá»›i há»— trá»£ multiple choice
        
        Returns:
            - Náº¿u cÃ³ 1 káº¿t quáº£: {"type": "kcn_detail", "kcn_info": {...}, ...}
            - Náº¿u cÃ³ nhiá»u káº¿t quáº£: {"type": "kcn_multiple_choice", "options": [...], ...}
            - Náº¿u khÃ´ng tÃ¬m tháº¥y: {"type": "kcn_detail_not_found", "message": "..."}
        """
        print(f"ğŸ” Processing KCN detail query: {question}")
        
        if not self.is_kcn_detail_query(question):
            print("âŒ Not a KCN detail query")
            return None
        
        # Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t tÃªn KCN
        specific_name = None
        query_type = None
        
        if self.llm:
            print("ğŸ¤– Using LLM for analysis")
            analysis = self._analyze_query_with_llm(question)
            
            if not analysis.get("is_industrial_query", False):
                print("âŒ LLM says not industrial query")
                return None
            
            if analysis.get("search_type") == "specific_name":
                specific_name = analysis.get("specific_name")
                query_type = analysis.get("query_type")
                print(f"ğŸ¯ LLM extracted: {specific_name}, type: {query_type}")
        
        # Fallback: extract name manually when no LLM or LLM failed
        if not specific_name:
            print("ğŸ”§ Using fallback extraction")
            specific_name = self._extract_kcn_name_fallback(question)
            query_type = None  # Let query_by_specific_name handle this
            print(f"ğŸ¯ Fallback extracted: {specific_name}")
        
        if not specific_name:
            print("âŒ Could not extract KCN name")
            return None
        
        # TÃ¬m thÃ´ng tin KCN tá»« structured data
        print(f"ğŸ” Searching for: {specific_name}")
        df_result = self.query_by_specific_name(specific_name, query_type)
        
        if df_result is None or df_result.empty:
            print(f"âŒ No results found for: {specific_name}")
            return {
                "type": "kcn_detail_not_found",
                "message": f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» '{specific_name}'. Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn hoáº·c thá»­ tÃ¬m kiáº¿m vá»›i tá»« khÃ³a khÃ¡c.",
                "query_name": specific_name
            }
        
        print(f"âœ… Found {len(df_result)} results")
        
        # ğŸ†• KIá»‚M TRA NHIá»€U Káº¾T QUáº¢ TRÃ™NG TÃŠN
        if len(df_result) > 1:
            print(f"ğŸ”€ Multiple results found, creating choice list")
            return self._create_multiple_choice_response(df_result, specific_name, query_type)
        
        # Chá»‰ cÃ³ 1 káº¿t quáº£ - tráº£ vá» chi tiáº¿t nhÆ° cÅ©
        return self._create_single_kcn_detail_response(df_result.iloc[0], specific_name, question)

    def _create_single_kcn_detail_response(self, row, specific_name: str, question: str) -> Dict:
        """
        Táº¡o response cho 1 KCN duy nháº¥t
        """
        cols = self.columns_map
        
        kcn_info = {
            "TÃªn": str(row.get(cols["name"], "")),
            "Äá»‹a chá»‰": str(row.get(cols["address"], "")),
            "Tá»‰nh/ThÃ nh phá»‘": str(row.get(cols["province"], "")),
            "Loáº¡i": str(row.get(cols["type"], "")),
            "Tá»•ng diá»‡n tÃ­ch": str(row.get(cols["area"], "")),
            "GiÃ¡ thuÃª Ä‘áº¥t": str(row.get(cols["rental_price"], "")),
            "Thá»i gian váº­n hÃ nh": str(row.get(cols["operation_time"], "")),
            "NgÃ nh nghá»": str(row.get(cols["industry"], "")),
        }
        
        print(f"ğŸ“‹ KCN Info: {kcn_info['TÃªn']}")
        
        # TÃ¬m tá»a Ä‘á»™
        coordinates = self._match_coordinates(kcn_info["TÃªn"])
        print(f"ğŸ“ Coordinates: {coordinates}")
        
        # Enhance vá»›i RAG
        rag_analysis = self._enhance_with_rag(kcn_info, question)
        
        result = {
            "type": "kcn_detail",
            "kcn_info": kcn_info,
            "coordinates": coordinates,
            "zoom_level": 16,  # Zoom ráº¥t gáº§n Ä‘á»ƒ tháº¥y chi tiáº¿t vá»‹ trÃ­
            "matched_name": kcn_info["TÃªn"],
            "query_name": specific_name,
            "message": f"ThÃ´ng tin chi tiáº¿t vá» {kcn_info['TÃªn']}"
        }
        
        # ThÃªm RAG analysis náº¿u cÃ³
        if rag_analysis:
            result["rag_analysis"] = rag_analysis
            result["has_rag"] = True
            print("âœ… Added RAG analysis")
        else:
            result["has_rag"] = False
            print("âš ï¸ No RAG analysis")
        
        print("âœ… KCN detail query processed successfully")
        return result