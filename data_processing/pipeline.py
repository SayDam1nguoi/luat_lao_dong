# data_processing/pipeline.py
from typing import Dict, Any, List
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage

from data_processing.cleaning import clean_question_remove_uris
from data_processing.language import detect_language_openai, convert_language
from data_processing.context_builder import build_context_from_hits
from system_prompts.pdf_reader_system import PDF_READER_SYS


def process_pdf_question(
    i: Dict[str, Any],
    *,
    llm,
    lang_llm,
    retriever,
    retriever_vsic_2018=None,
    excel_handler=None
) -> str:
    message = i["message"]
    history: List[BaseMessage] = i.get("history", [])

    clean_question = clean_question_remove_uris(message)
    user_lang = detect_language_openai(message, lang_llm)

    # 1ï¸âƒ£ Excel Æ°u tiÃªn
    if excel_handler:
        handled, excel_response = excel_handler.process_query(clean_question)
        if handled and excel_response:
            return (
                convert_language(excel_response, user_lang, lang_llm)
                if user_lang != "vi"
                else excel_response
            )

    # 2ï¸âƒ£ VectorDB â€“ VSIC hiá»‡n hÃ nh (2025)
    if retriever is None:
        msg = "VectorDB chÆ°a sáºµn sÃ ng."
        return convert_language(msg, user_lang, lang_llm)

    hits_2025 = retriever.invoke(clean_question)
    context_2025 = build_context_from_hits(hits_2025) if hits_2025 else ""

    # 3ï¸âƒ£ Hits VSIC 2018 â€“ Ä‘á»‘i chá»©ng
    hits_2018 = []
    context_2018 = ""
    if retriever_vsic_2018:
        hits_2018 = retriever_vsic_2018.invoke(clean_question)
        context_2018 = build_context_from_hits(hits_2018) if hits_2018 else (
            "âš ï¸ MÃ£ ngÃ nh nÃ y khÃ´ng Ä‘Æ°á»£c quy Ä‘á»‹nh trong Há»‡ thá»‘ng ngÃ nh kinh táº¿ Viá»‡t Nam "
            "ban hÃ nh theo Quyáº¿t Ä‘á»‹nh sá»‘ 27/2018/QÄ-TTg (VSIC 2018)."
        )

    # Náº¿u cáº£ 2025 vÃ  2018 Ä‘á»u khÃ´ng tÃ¬m tháº¥y
    if not hits_2025 and not hits_2018:
        msg = "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin ngÃ nh nghá» phÃ¹ há»£p."
        return convert_language(msg, user_lang, lang_llm)

    # Prefix hÆ°á»›ng dáº«n cho LLM
    system_prompt = (
        PDF_READER_SYS
        + f"\n\nğŸŒ NgÆ°á»i dÃ¹ng Ä‘ang dÃ¹ng ngÃ´n ngá»¯: '{user_lang}'."
        + "\n\nğŸŒŸ Äá»‘i chiáº¿u VSIC 2018 vÃ  2025 (náº¿u cÃ³): "
          "Pháº£i nÃªu rÃµ mÃ£ ngÃ nh, tÃªn ngÃ nh, phÃ¢n ngÃ nh, nhÃ³m ngÃ nh, vÃ  náº¿u thay Ä‘á»•i, tÃ¡ch/gá»™p, "
          "hoáº·c khÃ´ng tá»“n táº¡i, ghi chÃº rÃµ rÃ ng."
    )

    messages = [SystemMessage(content=system_prompt)]
    if history:
        messages.extend(history[-10:])

    # Gá»­i context VSIC 2025 vÃ  VSIC 2018 cho LLM
    messages.append(
        HumanMessage(
            content=f"""
CÃ¢u há»i: {clean_question}

Ná»™i dung VSIC 2025 (hiá»‡n hÃ nh):
{context_2025}

Ná»™i dung VSIC 2018 (Ä‘á»‘i chá»©ng):
{context_2018}

HÃ£y tráº£ lá»i Ä‘áº§y Ä‘á»§, bao gá»“m so sÃ¡nh giá»¯a VSIC 2025 vÃ  VSIC 2018.
HÃ£y tuÃ¢n thá»§ tuyá»‡t Ä‘á»‘i cÃ¡c quy Ä‘á»‹nh: khÃ´ng tÃ³m táº¯t, khÃ´ng bá» sÃ³t, nÃªu rÃµ cÄƒn cá»© phÃ¡p lÃ½.
HÃ£y tráº£ lá»i báº±ng ngÃ´n ngá»¯: {user_lang}.
"""
        )
    )

    response = llm.invoke(messages).content

    detected = detect_language_openai(response, lang_llm)
    if detected != user_lang:
        response = convert_language(response, user_lang, lang_llm)

    return response
